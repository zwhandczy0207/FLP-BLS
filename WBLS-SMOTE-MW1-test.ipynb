{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,recall_score,precision_score,f1_score,roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOC_BLANK</th>\n",
       "      <th>BRANCH_COUNT</th>\n",
       "      <th>CALL_PAIRS</th>\n",
       "      <th>LOC_CODE_AND_COMMENT</th>\n",
       "      <th>LOC_COMMENTS</th>\n",
       "      <th>CONDITION_COUNT</th>\n",
       "      <th>CYCLOMATIC_COMPLEXITY</th>\n",
       "      <th>CYCLOMATIC_DENSITY</th>\n",
       "      <th>DECISION_COUNT</th>\n",
       "      <th>DECISION_DENSITY</th>\n",
       "      <th>...</th>\n",
       "      <th>NODE_COUNT</th>\n",
       "      <th>NORMALIZED_CYLOMATIC_COMPLEXITY</th>\n",
       "      <th>NUM_OPERANDS</th>\n",
       "      <th>NUM_OPERATORS</th>\n",
       "      <th>NUM_UNIQUE_OPERANDS</th>\n",
       "      <th>NUM_UNIQUE_OPERATORS</th>\n",
       "      <th>NUMBER_OF_LINES</th>\n",
       "      <th>PERCENT_COMMENTS</th>\n",
       "      <th>LOC_TOTAL</th>\n",
       "      <th>Defective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.16</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.11</td>\n",
       "      <td>37</td>\n",
       "      <td>47</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>21.88</td>\n",
       "      <td>25</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>0.30</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>0.24</td>\n",
       "      <td>75</td>\n",
       "      <td>86</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>45</td>\n",
       "      <td>7.69</td>\n",
       "      <td>37</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.33</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.19</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>30.77</td>\n",
       "      <td>9</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.19</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0.09</td>\n",
       "      <td>22</td>\n",
       "      <td>33</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>35</td>\n",
       "      <td>48.39</td>\n",
       "      <td>16</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.43</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0.19</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>41.67</td>\n",
       "      <td>7</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LOC_BLANK  BRANCH_COUNT  CALL_PAIRS  LOC_CODE_AND_COMMENT  LOC_COMMENTS  \\\n",
       "0          5             7          13                     0             7   \n",
       "1          5            21           3                     1             2   \n",
       "2          2             5           0                     0             4   \n",
       "3          3             5           3                     0            15   \n",
       "4          3             5           2                     0             5   \n",
       "\n",
       "   CONDITION_COUNT  CYCLOMATIC_COMPLEXITY  CYCLOMATIC_DENSITY  DECISION_COUNT  \\\n",
       "0                8                      4                0.16               4   \n",
       "1               24                     11                0.30               4   \n",
       "2                8                      3                0.33               4   \n",
       "3                8                      3                0.19               4   \n",
       "4                8                      3                0.43               4   \n",
       "\n",
       "   DECISION_DENSITY  ...  NODE_COUNT  NORMALIZED_CYLOMATIC_COMPLEXITY  \\\n",
       "0               2.0  ...          24                             0.11   \n",
       "1               6.0  ...          23                             0.24   \n",
       "2               2.0  ...           9                             0.19   \n",
       "3               2.0  ...          12                             0.09   \n",
       "4               2.0  ...          12                             0.19   \n",
       "\n",
       "   NUM_OPERANDS  NUM_OPERATORS  NUM_UNIQUE_OPERANDS  NUM_UNIQUE_OPERATORS  \\\n",
       "0            37             47                   28                     9   \n",
       "1            75             86                   32                    16   \n",
       "2            10             17                    6                     9   \n",
       "3            22             33                   12                    14   \n",
       "4            19             22                    8                    10   \n",
       "\n",
       "   NUMBER_OF_LINES  PERCENT_COMMENTS  LOC_TOTAL  Defective  \n",
       "0               38             21.88         25          N  \n",
       "1               45              7.69         37          N  \n",
       "2               16             30.77          9          N  \n",
       "3               35             48.39         16          Y  \n",
       "4               16             41.67          7          N  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv(\"../../dataset/NASA/mw1.csv\")\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOC_BLANK</th>\n",
       "      <th>BRANCH_COUNT</th>\n",
       "      <th>CALL_PAIRS</th>\n",
       "      <th>LOC_CODE_AND_COMMENT</th>\n",
       "      <th>LOC_COMMENTS</th>\n",
       "      <th>CONDITION_COUNT</th>\n",
       "      <th>CYCLOMATIC_COMPLEXITY</th>\n",
       "      <th>CYCLOMATIC_DENSITY</th>\n",
       "      <th>DECISION_COUNT</th>\n",
       "      <th>DECISION_DENSITY</th>\n",
       "      <th>...</th>\n",
       "      <th>MULTIPLE_CONDITION_COUNT</th>\n",
       "      <th>NODE_COUNT</th>\n",
       "      <th>NORMALIZED_CYLOMATIC_COMPLEXITY</th>\n",
       "      <th>NUM_OPERANDS</th>\n",
       "      <th>NUM_OPERATORS</th>\n",
       "      <th>NUM_UNIQUE_OPERANDS</th>\n",
       "      <th>NUM_UNIQUE_OPERATORS</th>\n",
       "      <th>NUMBER_OF_LINES</th>\n",
       "      <th>PERCENT_COMMENTS</th>\n",
       "      <th>LOC_TOTAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.415020</td>\n",
       "      <td>10.280632</td>\n",
       "      <td>5.608696</td>\n",
       "      <td>0.264822</td>\n",
       "      <td>5.367589</td>\n",
       "      <td>14.482213</td>\n",
       "      <td>6.019763</td>\n",
       "      <td>0.242767</td>\n",
       "      <td>6.418972</td>\n",
       "      <td>2.287352</td>\n",
       "      <td>...</td>\n",
       "      <td>7.375494</td>\n",
       "      <td>22.355731</td>\n",
       "      <td>0.166680</td>\n",
       "      <td>46.683794</td>\n",
       "      <td>59.328063</td>\n",
       "      <td>25.849802</td>\n",
       "      <td>13.529644</td>\n",
       "      <td>39.632411</td>\n",
       "      <td>16.308933</td>\n",
       "      <td>26.849802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.943992</td>\n",
       "      <td>9.023575</td>\n",
       "      <td>4.849423</td>\n",
       "      <td>1.816215</td>\n",
       "      <td>6.186523</td>\n",
       "      <td>13.941085</td>\n",
       "      <td>5.179669</td>\n",
       "      <td>0.115560</td>\n",
       "      <td>6.018355</td>\n",
       "      <td>1.057111</td>\n",
       "      <td>...</td>\n",
       "      <td>7.391900</td>\n",
       "      <td>17.301709</td>\n",
       "      <td>0.085635</td>\n",
       "      <td>38.372480</td>\n",
       "      <td>48.688016</td>\n",
       "      <td>17.206991</td>\n",
       "      <td>6.541391</td>\n",
       "      <td>29.401221</td>\n",
       "      <td>14.031681</td>\n",
       "      <td>19.824857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>14.710000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>23.080000</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>65.630000</td>\n",
       "      <td>112.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        LOC_BLANK  BRANCH_COUNT  CALL_PAIRS  LOC_CODE_AND_COMMENT  \\\n",
       "count  253.000000    253.000000  253.000000            253.000000   \n",
       "mean     6.415020     10.280632    5.608696              0.264822   \n",
       "std      5.943992      9.023575    4.849423              1.816215   \n",
       "min      0.000000      3.000000    0.000000              0.000000   \n",
       "25%      2.000000      5.000000    2.000000              0.000000   \n",
       "50%      4.000000      7.000000    4.000000              0.000000   \n",
       "75%      9.000000     13.000000    7.000000              0.000000   \n",
       "max     34.000000     50.000000   25.000000             16.000000   \n",
       "\n",
       "       LOC_COMMENTS  CONDITION_COUNT  CYCLOMATIC_COMPLEXITY  \\\n",
       "count    253.000000       253.000000             253.000000   \n",
       "mean       5.367589        14.482213               6.019763   \n",
       "std        6.186523        13.941085               5.179669   \n",
       "min        0.000000         4.000000               2.000000   \n",
       "25%        1.000000         4.000000               3.000000   \n",
       "50%        4.000000         8.000000               4.000000   \n",
       "75%        7.000000        18.000000               7.000000   \n",
       "max       42.000000        82.000000              28.000000   \n",
       "\n",
       "       CYCLOMATIC_DENSITY  DECISION_COUNT  DECISION_DENSITY  ...  \\\n",
       "count          253.000000      253.000000        253.000000  ...   \n",
       "mean             0.242767        6.418972          2.287352  ...   \n",
       "std              0.115560        6.018355          1.057111  ...   \n",
       "min              0.060000        2.000000          2.000000  ...   \n",
       "25%              0.160000        2.000000          2.000000  ...   \n",
       "50%              0.220000        4.000000          2.000000  ...   \n",
       "75%              0.300000        8.000000          2.200000  ...   \n",
       "max              0.790000       36.000000         11.500000  ...   \n",
       "\n",
       "       MULTIPLE_CONDITION_COUNT  NODE_COUNT  NORMALIZED_CYLOMATIC_COMPLEXITY  \\\n",
       "count                253.000000  253.000000                       253.000000   \n",
       "mean                   7.375494   22.355731                         0.166680   \n",
       "std                    7.391900   17.301709                         0.085635   \n",
       "min                    2.000000    5.000000                         0.040000   \n",
       "25%                    2.000000   11.000000                         0.110000   \n",
       "50%                    4.000000   16.000000                         0.150000   \n",
       "75%                    9.000000   28.000000                         0.200000   \n",
       "max                   48.000000  110.000000                         0.690000   \n",
       "\n",
       "       NUM_OPERANDS  NUM_OPERATORS  NUM_UNIQUE_OPERANDS  NUM_UNIQUE_OPERATORS  \\\n",
       "count    253.000000     253.000000           253.000000            253.000000   \n",
       "mean      46.683794      59.328063            25.849802             13.529644   \n",
       "std       38.372480      48.688016            17.206991              6.541391   \n",
       "min        4.000000       6.000000             3.000000              4.000000   \n",
       "25%       19.000000      25.000000            13.000000              9.000000   \n",
       "50%       33.000000      43.000000            21.000000             12.000000   \n",
       "75%       61.000000      80.000000            36.000000             17.000000   \n",
       "max      226.000000     303.000000            94.000000             44.000000   \n",
       "\n",
       "       NUMBER_OF_LINES  PERCENT_COMMENTS   LOC_TOTAL  \n",
       "count       253.000000        253.000000  253.000000  \n",
       "mean         39.632411         16.308933   26.849802  \n",
       "std          29.401221         14.031681   19.824857  \n",
       "min           5.000000          0.000000    4.000000  \n",
       "25%          18.000000          6.250000   12.000000  \n",
       "50%          30.000000         14.710000   20.000000  \n",
       "75%          51.000000         23.080000   37.000000  \n",
       "max         171.000000         65.630000  112.000000  \n",
       "\n",
       "[8 rows x 37 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 38)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 21, 3, 1, 2, 24, 11, 0.3, 4, 6.0, 2, 0.18, 32, 10, 0, 36, 1,\n",
       "       47.96, 18.75, 16859.61, 0.3, 161, 0.05, 936.64, 899.18, 0.91, 10,\n",
       "       12, 23, 0.24, 75, 86, 32, 16, 45, 7.69, 37, 0], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2=data1.values\n",
    "for i in range(253):\n",
    "    if data2[i][37]==\"Y\":\n",
    "        data2[i][37]=1\n",
    "    else:\n",
    "        data2[i][37]=0\n",
    "data2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(data2).astype(float)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.  ,  7.  , 13.  , ..., 38.  , 21.88, 25.  ],\n",
       "       [ 5.  , 21.  ,  3.  , ..., 45.  ,  7.69, 37.  ],\n",
       "       [ 2.  ,  5.  ,  0.  , ..., 16.  , 30.77,  9.  ],\n",
       "       ...,\n",
       "       [10.  , 10.  ,  6.  , ..., 93.  , 25.61, 61.  ],\n",
       "       [10.  ,  5.  ,  7.  , ..., 44.  , 21.21, 26.  ],\n",
       "       [ 6.  , 25.  ,  3.  , ..., 55.  , 18.75, 39.  ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,:37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=X[:,37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X[:,0:37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((452, 37), (452,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
    "#os =  RandomOverSampler()\n",
    "X_res, y_res = SMOTE().fit_resample(X, y)\n",
    "X_res.shape,y_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(452, 37)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res.shape\n",
    "#X_res=X_res.reshape(898,21,1)\n",
    "#X_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import csv\n",
    "import time\n",
    "\n",
    "def show_accuracy(predictLabel,Label):\n",
    "    Label = np.ravel(Label).tolist()\n",
    "    predictLabel = predictLabel.tolist()\n",
    "    count = 0\n",
    "    for i in range(len(Label)):\n",
    "        if Label[i] == predictLabel[i]:\n",
    "            count += 1\n",
    "    return (round(count/len(Label),5))\n",
    "\n",
    "class node_generator(object):\n",
    "    def __init__(self, whiten = False):\n",
    "        self.Wlist = []\n",
    "        self.blist = []\n",
    "        self.function_num = 0\n",
    "        self.whiten = whiten\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1.0/(1 + np.exp(-x))\n",
    "\n",
    "    def relu(self, x):\n",
    "        return np.maximum(x, 0)\n",
    "\n",
    "    def tanh(self, x):\n",
    "        return (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x))\n",
    "\n",
    "    def linear(self, x):\n",
    "        return x\n",
    "\n",
    "    def orth(self, W):\n",
    "        \"\"\"\n",
    "        目前看来，这个函数应该配合下一个generator函数是生成权重的\n",
    "        \"\"\"\n",
    "        for i in range(0, W.shape[1]):\n",
    "            w = np.mat(W[:,i].copy()).T\n",
    "            w_sum = 0\n",
    "            for j in range(i):\n",
    "                wj = np.mat(W[:,j].copy()).T\n",
    "                w_sum += (w.T.dot(wj))[0,0]*wj\n",
    "            w -= w_sum\n",
    "            w = w/np.sqrt(w.T.dot(w))\n",
    "            W[:,i] = np.ravel(w)\n",
    "\n",
    "        return W\n",
    "\n",
    "    def generator(self, shape, times):\n",
    "        for i in range(times):\n",
    "            random.seed(i)\n",
    "            W = 2*np.random.random(size=shape)-1\n",
    "            if self.whiten == True:\n",
    "                W = self.orth(W)   # 只在增强层使用\n",
    "            b = 2*np.random.random() -1\n",
    "            yield (W, b)\n",
    "\n",
    "    def generator_nodes(self, data, times, batchsize, function_num):\n",
    "        # 按照bls的理论，mapping layer是输入乘以不同的权重加上不同的偏差之后得到的\n",
    "        # 若干组，所以，权重是一个列表，每一个元素可作为权重与输入相乘\n",
    "        self.Wlist = [elem[0] for elem in self.generator((data.shape[1], batchsize), times)]\n",
    "        self.blist = [elem[1] for elem in self.generator((data.shape[1], batchsize), times)]\n",
    "\n",
    "        self.function_num = {'linear':self.linear,\n",
    "                        'sigmoid': self.sigmoid,\n",
    "                        'tanh':self.tanh,\n",
    "                        'relu':self.relu }[function_num]  # 激活函数供不同的层选择\n",
    "        # 下面就是先得到一组mapping nodes，再不断叠加，得到len(Wlist)组mapping nodes\n",
    "        nodes = self.function_num(data.dot(self.Wlist[0]) + self.blist[0])\n",
    "        for i in range(1, len(self.Wlist)):\n",
    "            nodes = np.column_stack((nodes, self.function_num(data.dot(self.Wlist[i])+self.blist[i])))\n",
    "        return nodes\n",
    "\n",
    "    def transform(self,testdata):\n",
    "        testnodes = self.function_num(testdata.dot(self.Wlist[0])+self.blist[0])\n",
    "        for i in range(1,len(self.Wlist)):\n",
    "            testnodes = np.column_stack((testnodes, self.function_num(testdata.dot(self.Wlist[i])+self.blist[i])))\n",
    "        return testnodes\n",
    "\n",
    "class scaler:\n",
    "    def __init__(self):\n",
    "        self._mean = 0\n",
    "        self._std = 0\n",
    "    \n",
    "    def fit_transform(self,traindata):\n",
    "        self._mean = traindata.mean(axis = 0)\n",
    "        self._std = traindata.std(axis = 0)\n",
    "        return (traindata-self._mean)/(self._std+0.001)\n",
    "    \n",
    "    def transform(self,testdata):\n",
    "        return (testdata-self._mean)/(self._std+0.001)\n",
    "\n",
    "class broadnet:\n",
    "    def __init__(self, \n",
    "                 maptimes = 10, \n",
    "                 enhencetimes = 10,\n",
    "                 map_function = 'linear',\n",
    "                 enhence_function = 'linear',\n",
    "                 batchsize = 'auto', \n",
    "                 reg = 0.001):\n",
    "        \n",
    "        self._maptimes = maptimes\n",
    "        self._enhencetimes = enhencetimes\n",
    "        self._batchsize = batchsize\n",
    "        self._reg = reg\n",
    "        self._map_function = map_function\n",
    "        self._enhence_function = enhence_function\n",
    "        \n",
    "        self.W = 0\n",
    "        self.pesuedoinverse = 0\n",
    "        self.normalscaler = scaler()\n",
    "        self.onehotencoder = preprocessing.OneHotEncoder(sparse = False)\n",
    "        self.mapping_generator = node_generator()\n",
    "        self.enhence_generator = node_generator(whiten = True)\n",
    "\n",
    "    def fit(self,data,label,weight):\n",
    "        if self._batchsize == 'auto':\n",
    "            self._batchsize = data.shape[1]\n",
    "        data = self.normalscaler.fit_transform(data)\n",
    "        label = self.onehotencoder.fit_transform(np.mat(label).T)\n",
    "        \n",
    "        mappingdata = self.mapping_generator.generator_nodes(data,self._maptimes,self._batchsize,self._map_function)\n",
    "        enhencedata = self.enhence_generator.generator_nodes(mappingdata,self._enhencetimes,self._batchsize,self._enhence_function)\n",
    "        \n",
    "        #print('number of mapping nodes {0}, number of enhence nodes {1}'.format(mappingdata.shape[1],enhencedata.shape[1]))\n",
    "        #print('mapping nodes maxvalue {0} minvalue {1} '.format(round(np.max(mappingdata),5),round(np.min(mappingdata),5)))\n",
    "        #print('enhence nodes maxvalue {0} minvalue {1} '.format(round(np.max(enhencedata),5),round(np.min(enhencedata),5)))\n",
    "        \n",
    "        inputdata = np.column_stack((mappingdata,enhencedata))\n",
    "        pesuedoinverse = self.pinv(inputdata,self._reg,weight)\n",
    "        self.W =  pesuedoinverse.dot(label)\n",
    "        \n",
    "        #print('W:', self.W)\n",
    "        #print('W:', self.W.shape)  \n",
    "    \n",
    "    #改写伪逆矩阵算法，将权重输入\n",
    "    def pinv(self,A,reg,weight):\n",
    "        return np.mat(reg*np.eye(A.shape[1])+A.T.dot(weight).dot(A)).I.dot(A.T).dot(weight)\n",
    "    \n",
    "    def decode(self,Y_onehot):\n",
    "        Y = []\n",
    "        for i in range(Y_onehot.shape[0]):\n",
    "            lis = np.ravel(Y_onehot[i,:]).tolist()\n",
    "            Y.append(lis.index(max(lis)))\n",
    "        return np.array(Y)\n",
    "    \n",
    "    def accuracy(self,predictlabel,label):\n",
    "        label = np.ravel(label).tolist()\n",
    "        predictlabel = predictlabel.tolist()\n",
    "        count = 0\n",
    "        for i in range(len(label)):\n",
    "            if label[i] == predictlabel[i]:\n",
    "                count += 1\n",
    "        return (round(count/len(label),5))\n",
    "        \n",
    "    def predict(self,testdata):\n",
    "        testdata = self.normalscaler.transform(testdata)\n",
    "        test_mappingdata = self.mapping_generator.transform(testdata)\n",
    "        test_enhencedata = self.enhence_generator.transform(test_mappingdata)\n",
    "        \n",
    "        test_inputdata = np.column_stack((test_mappingdata,test_enhencedata)) \n",
    "        #print('*predictlabel shape:',self.decode(test_inputdata.dot(self.W)).shape)\n",
    "        #print('*predictlabel:', self.decode(test_inputdata.dot(self.W)))\n",
    "        #print('*accuracy:',show_accuracy(self.decode(test_inputdata.dot(self.W)),testlabel))\n",
    "        return self.decode(test_inputdata.dot(self.W))\n",
    "    \n",
    "    def addWeight(self,trainlabel):\n",
    "        #对BLS设置加权，按照训练集中的label比例进行权重设置\n",
    "        #求训练数据集中label为1的个数\n",
    "        count=0\n",
    "        for z in range(len(trainlabel)):\n",
    "            #print ('个数 %d ' %z)\n",
    "            #print('k_train_label:', k_train_label[z])\n",
    "            if trainlabel[z]==1:\n",
    "                count=count+1\n",
    "        #print ('label为1的个数 %d ' %j)\n",
    "        #print(count)\n",
    "        #print(k_train_label.shape)\n",
    "        #print(len(k_train_label))\n",
    "        #权重设置 \n",
    "        weight = np.zeros((len(trainlabel),len(trainlabel)))\n",
    "        for i in range(len(trainlabel)):\n",
    "            if trainlabel[i]==1:\n",
    "                #weight[i,i]=0.618/count\n",
    "                weight[i,i]=2*(len(trainlabel)-count)/len(trainlabel)\n",
    "            else:\n",
    "                #weight[i,i]=1/(len(k_train_label)-count)\n",
    "                weight[i,i]=2*count/len(trainlabel)\n",
    "        #print('Weight:', weight)\n",
    "        return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将数据集划分为训练集和测试集\n",
    "#traindata,testdata,trainlabel,testlabel = train_test_split(X_res,y_res,test_size=0.2,random_state = 0)\n",
    "#print(traindata.shape,trainlabel.shape,testdata.shape,testlabel.shape)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2)\n",
    "#y_train = np_utils.to_categorical(y_train)\n",
    "#y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainingTime：3.402488,acc：0.911504,fmeasure：0.911017,auc：0.913793,recall：0.911504,MCC：0.836819,Gmeasure：0.913790\n",
      "trainingTime：3.426042,acc：0.938053,fmeasure：0.937040,auc：0.923913,recall：0.938053,MCC：0.876143,Gmeasure：0.923805\n",
      "trainingTime：3.447589,acc：0.938053,fmeasure：0.937426,auc：0.931373,recall：0.938053,MCC：0.880466,Gmeasure：0.931349\n",
      "trainingTime：3.444044,acc：0.867257,fmeasure：0.866945,auc：0.880952,recall：0.867257,MCC：0.765559,Gmeasure：0.880846\n",
      "trainingTime：3.445863,acc：0.902655,fmeasure：0.903159,auc：0.915385,recall：0.902655,MCC：0.822119,Gmeasure：0.915296\n",
      "trainingTime：3.466049,acc：0.946903,fmeasure：0.946878,auc：0.949153,recall：0.946903,MCC：0.899152,Gmeasure：0.949150\n",
      "trainingTime：3.484812,acc：0.902655,fmeasure：0.901810,auc：0.903509,recall：0.902655,MCC：0.821293,Gmeasure：0.903508\n",
      "trainingTime：3.475757,acc：0.840708,fmeasure：0.836366,auc：0.834118,recall：0.840708,MCC：0.706530,Gmeasure：0.834092\n",
      "trainingTime：3.463539,acc：0.902655,fmeasure：0.901810,auc：0.903509,recall：0.902655,MCC：0.821293,Gmeasure：0.903508\n",
      "trainingTime：3.462926,acc：0.929204,fmeasure：0.929070,auc：0.932203,recall：0.929204,MCC：0.867681,Gmeasure：0.932199\n"
     ]
    }
   ],
   "source": [
    "Evaluat_list=[]\n",
    "for i in np.arange(0,10):\n",
    "    #将数据集划分为训练集和测试集\n",
    "    traindata,testdata,trainlabel,testlabel = train_test_split(X_res,y_res,test_size=0.25,random_state = i)\n",
    "    bls = broadnet(maptimes = 30, \n",
    "               enhencetimes = 15,\n",
    "               map_function = 'relu',\n",
    "               enhence_function = 'relu',\n",
    "               batchsize =100,\n",
    "               reg = 0.001)\n",
    "\n",
    "    #根据训练数据设置权重\n",
    "    weight=bls.addWeight(trainlabel)\n",
    "\n",
    "    #训练\n",
    "    starttime = datetime.datetime.now()\n",
    "    bls.fit(traindata,trainlabel,weight)\n",
    "    endtime = datetime.datetime.now()\n",
    "    trainingTime=(endtime - starttime).total_seconds()\n",
    "    #print('the training time of BLS is {0} seconds'.format((endtime - starttime).total_seconds()))\n",
    "\n",
    "    #预测\n",
    "    predictlabel = bls.predict(testdata)\n",
    "\n",
    "    #评价指标计算\n",
    "    acc=accuracy_score(testlabel,predictlabel,normalize=True)\n",
    "    fmeasure=f1_score(testlabel,predictlabel, average='weighted', labels=np.unique(testlabel))\n",
    "    try:\n",
    "        auc=roc_auc_score(testlabel,predictlabel, average='macro', sample_weight=None)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    MCC=matthews_corrcoef(testlabel,predictlabel)\n",
    "    Gmeasure=geometric_mean_score(testlabel,predictlabel, average='weighted')\n",
    "    recall=recall_score(testlabel, predictlabel, average='weighted')\n",
    "\n",
    "    print('trainingTime：%f,acc：%f,fmeasure：%f,auc：%f,recall：%f,MCC：%f,Gmeasure：%f'%(trainingTime,acc,fmeasure,auc,recall,MCC,Gmeasure))\n",
    "    Evaluat_tuple=(trainingTime,acc,fmeasure,auc,recall,MCC,Gmeasure)    \n",
    "    Evaluat_list.append(Evaluat_tuple)\n",
    "\n",
    "# 表头\n",
    "header = ['trainTime', 'acc', 'fmeasure', 'auc','recall', 'MCC', 'Gmeasure']\n",
    "with open('./data_remember/0.75WBLS_Smote_MW1_Evaluat.csv', 'w', encoding='utf-8', newline='') as file_obj:\n",
    "    # 创建对象\n",
    "    writer = csv.writer(file_obj)\n",
    "    # 写表头\n",
    "    writer.writerow(header)\n",
    "    # 3.写入数据(一次性写入多行)\n",
    "    writer.writerows(Evaluat_list)\n",
    "\n",
    "\n",
    "    #sio.savemat('./data_remember/WBLS_Smote_CM1_test.mat',{'time':format((endtime - starttime).total_seconds()),'acc':acc,'f1':fmeasure,'auc':auc,'mcc':MCC,'Gm':Gmeasure})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf01",
   "language": "python",
   "name": "tf01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
