{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,recall_score,precision_score,f1_score,roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRANCH_COUNT</th>\n",
       "      <th>CALL_PAIRS</th>\n",
       "      <th>LOC_CODE_AND_COMMENT</th>\n",
       "      <th>LOC_COMMENTS</th>\n",
       "      <th>CONDITION_COUNT</th>\n",
       "      <th>CYCLOMATIC_COMPLEXITY</th>\n",
       "      <th>CYCLOMATIC_DENSITY</th>\n",
       "      <th>DECISION_COUNT</th>\n",
       "      <th>DECISION_DENSITY</th>\n",
       "      <th>DESIGN_COMPLEXITY</th>\n",
       "      <th>...</th>\n",
       "      <th>NODE_COUNT</th>\n",
       "      <th>NORMALIZED_CYLOMATIC_COMPLEXITY</th>\n",
       "      <th>NUM_OPERANDS</th>\n",
       "      <th>NUM_OPERATORS</th>\n",
       "      <th>NUM_UNIQUE_OPERANDS</th>\n",
       "      <th>NUM_UNIQUE_OPERATORS</th>\n",
       "      <th>NUMBER_OF_LINES</th>\n",
       "      <th>PERCENT_COMMENTS</th>\n",
       "      <th>LOC_TOTAL</th>\n",
       "      <th>Defective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0.24</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0.20</td>\n",
       "      <td>37</td>\n",
       "      <td>54</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>82.35</td>\n",
       "      <td>17</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0.24</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>0.20</td>\n",
       "      <td>39</td>\n",
       "      <td>56</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>82.35</td>\n",
       "      <td>17</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0.80</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>80.00</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>50.00</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>93.75</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BRANCH_COUNT  CALL_PAIRS  LOC_CODE_AND_COMMENT  LOC_COMMENTS  \\\n",
       "0             7           1                    14             0   \n",
       "1             7           2                    14             0   \n",
       "2             7           0                     4             0   \n",
       "3             3           0                     1             0   \n",
       "4             3           0                     1            14   \n",
       "\n",
       "   CONDITION_COUNT  CYCLOMATIC_COMPLEXITY  CYCLOMATIC_DENSITY  DECISION_COUNT  \\\n",
       "0               12                      4                0.24               6   \n",
       "1               12                      4                0.24               6   \n",
       "2               12                      4                0.80               6   \n",
       "3                4                      2                1.00               2   \n",
       "4                4                      2                1.00               2   \n",
       "\n",
       "   DECISION_DENSITY  DESIGN_COMPLEXITY  ...  NODE_COUNT  \\\n",
       "0               2.0                  1  ...          12   \n",
       "1               2.0                  2  ...          13   \n",
       "2               2.0                  1  ...          10   \n",
       "3               2.0                  1  ...           5   \n",
       "4               2.0                  1  ...           5   \n",
       "\n",
       "   NORMALIZED_CYLOMATIC_COMPLEXITY  NUM_OPERANDS  NUM_OPERATORS  \\\n",
       "0                             0.20            37             54   \n",
       "1                             0.20            39             56   \n",
       "2                             0.50             6             11   \n",
       "3                             0.50             2              5   \n",
       "4                             0.11             2              5   \n",
       "\n",
       "   NUM_UNIQUE_OPERANDS  NUM_UNIQUE_OPERATORS  NUMBER_OF_LINES  \\\n",
       "0                    9                    14               20   \n",
       "1                   10                    14               20   \n",
       "2                    3                     7                8   \n",
       "3                    2                     5                4   \n",
       "4                    2                     5               18   \n",
       "\n",
       "   PERCENT_COMMENTS  LOC_TOTAL  Defective  \n",
       "0             82.35         17          N  \n",
       "1             82.35         17          N  \n",
       "2             80.00          5          N  \n",
       "3             50.00          2          N  \n",
       "4             93.75          2          N  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv(\"../../dataset/NASA/PC2.csv\")\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRANCH_COUNT</th>\n",
       "      <th>CALL_PAIRS</th>\n",
       "      <th>LOC_CODE_AND_COMMENT</th>\n",
       "      <th>LOC_COMMENTS</th>\n",
       "      <th>CONDITION_COUNT</th>\n",
       "      <th>CYCLOMATIC_COMPLEXITY</th>\n",
       "      <th>CYCLOMATIC_DENSITY</th>\n",
       "      <th>DECISION_COUNT</th>\n",
       "      <th>DECISION_DENSITY</th>\n",
       "      <th>DESIGN_COMPLEXITY</th>\n",
       "      <th>...</th>\n",
       "      <th>MULTIPLE_CONDITION_COUNT</th>\n",
       "      <th>NODE_COUNT</th>\n",
       "      <th>NORMALIZED_CYLOMATIC_COMPLEXITY</th>\n",
       "      <th>NUM_OPERANDS</th>\n",
       "      <th>NUM_OPERATORS</th>\n",
       "      <th>NUM_UNIQUE_OPERANDS</th>\n",
       "      <th>NUM_UNIQUE_OPERATORS</th>\n",
       "      <th>NUMBER_OF_LINES</th>\n",
       "      <th>PERCENT_COMMENTS</th>\n",
       "      <th>LOC_TOTAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.850636</td>\n",
       "      <td>2.945077</td>\n",
       "      <td>9.770261</td>\n",
       "      <td>3.058272</td>\n",
       "      <td>9.259210</td>\n",
       "      <td>3.474213</td>\n",
       "      <td>0.445693</td>\n",
       "      <td>4.392498</td>\n",
       "      <td>2.116048</td>\n",
       "      <td>2.694575</td>\n",
       "      <td>...</td>\n",
       "      <td>4.630275</td>\n",
       "      <td>13.087743</td>\n",
       "      <td>0.275177</td>\n",
       "      <td>21.656397</td>\n",
       "      <td>31.983925</td>\n",
       "      <td>9.231078</td>\n",
       "      <td>10.884796</td>\n",
       "      <td>17.373074</td>\n",
       "      <td>76.033369</td>\n",
       "      <td>11.864032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.876981</td>\n",
       "      <td>4.197814</td>\n",
       "      <td>21.644059</td>\n",
       "      <td>9.979131</td>\n",
       "      <td>18.309096</td>\n",
       "      <td>5.073736</td>\n",
       "      <td>0.236106</td>\n",
       "      <td>8.864711</td>\n",
       "      <td>0.328705</td>\n",
       "      <td>4.120888</td>\n",
       "      <td>...</td>\n",
       "      <td>9.154978</td>\n",
       "      <td>20.526278</td>\n",
       "      <td>0.116308</td>\n",
       "      <td>42.766455</td>\n",
       "      <td>62.230166</td>\n",
       "      <td>13.196272</td>\n",
       "      <td>4.807430</td>\n",
       "      <td>31.859582</td>\n",
       "      <td>13.509902</td>\n",
       "      <td>24.711057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>85.710000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>287.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>843.000000</td>\n",
       "      <td>1198.000000</td>\n",
       "      <td>245.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>98.250000</td>\n",
       "      <td>663.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       BRANCH_COUNT   CALL_PAIRS  LOC_CODE_AND_COMMENT  LOC_COMMENTS  \\\n",
       "count   1493.000000  1493.000000           1493.000000   1493.000000   \n",
       "mean       5.850636     2.945077              9.770261      3.058272   \n",
       "std        9.876981     4.197814             21.644059      9.979131   \n",
       "min        1.000000     0.000000              0.000000      0.000000   \n",
       "25%        3.000000     1.000000              3.000000      0.000000   \n",
       "50%        3.000000     2.000000              5.000000      0.000000   \n",
       "75%        7.000000     4.000000             11.000000      1.000000   \n",
       "max      287.000000    74.000000            558.000000    111.000000   \n",
       "\n",
       "       CONDITION_COUNT  CYCLOMATIC_COMPLEXITY  CYCLOMATIC_DENSITY  \\\n",
       "count      1493.000000            1493.000000         1493.000000   \n",
       "mean          9.259210               3.474213            0.445693   \n",
       "std          18.309096               5.073736            0.236106   \n",
       "min           4.000000               1.000000            0.030000   \n",
       "25%           4.000000               2.000000            0.270000   \n",
       "50%           6.000000               2.000000            0.400000   \n",
       "75%          12.000000               4.000000            0.570000   \n",
       "max         570.000000             144.000000            1.000000   \n",
       "\n",
       "       DECISION_COUNT  DECISION_DENSITY  DESIGN_COMPLEXITY  ...  \\\n",
       "count     1493.000000       1493.000000        1493.000000  ...   \n",
       "mean         4.392498          2.116048           2.694575  ...   \n",
       "std          8.864711          0.328705           4.120888  ...   \n",
       "min          2.000000          2.000000           1.000000  ...   \n",
       "25%          2.000000          2.000000           1.000000  ...   \n",
       "50%          2.000000          2.000000           2.000000  ...   \n",
       "75%          6.000000          2.000000           3.000000  ...   \n",
       "max        284.000000          7.000000         115.000000  ...   \n",
       "\n",
       "       MULTIPLE_CONDITION_COUNT   NODE_COUNT  NORMALIZED_CYLOMATIC_COMPLEXITY  \\\n",
       "count               1493.000000  1493.000000                      1493.000000   \n",
       "mean                   4.630275    13.087743                         0.275177   \n",
       "std                    9.154978    20.526278                         0.116308   \n",
       "min                    2.000000     2.000000                         0.020000   \n",
       "25%                    2.000000     6.000000                         0.200000   \n",
       "50%                    3.000000     8.000000                         0.250000   \n",
       "75%                    6.000000    14.000000                         0.330000   \n",
       "max                  285.000000   568.000000                         0.600000   \n",
       "\n",
       "       NUM_OPERANDS  NUM_OPERATORS  NUM_UNIQUE_OPERANDS  NUM_UNIQUE_OPERATORS  \\\n",
       "count   1493.000000    1493.000000          1493.000000           1493.000000   \n",
       "mean      21.656397      31.983925             9.231078             10.884796   \n",
       "std       42.766455      62.230166            13.196272              4.807430   \n",
       "min        1.000000       4.000000             1.000000              4.000000   \n",
       "25%        6.000000      10.000000             4.000000              7.000000   \n",
       "50%       11.000000      15.000000             7.000000              9.000000   \n",
       "75%       24.000000      34.000000            11.000000             14.000000   \n",
       "max      843.000000    1198.000000           245.000000             46.000000   \n",
       "\n",
       "       NUMBER_OF_LINES  PERCENT_COMMENTS    LOC_TOTAL  \n",
       "count      1493.000000       1493.000000  1493.000000  \n",
       "mean         17.373074         76.033369    11.864032  \n",
       "std          31.859582         13.509902    24.711057  \n",
       "min           4.000000          0.000000     2.000000  \n",
       "25%           6.000000         70.000000     4.000000  \n",
       "50%          10.000000         80.000000     7.000000  \n",
       "75%          18.000000         85.710000    13.000000  \n",
       "max         776.000000         98.250000   663.000000  \n",
       "\n",
       "[8 rows x 36 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1493, 37)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 14, 0, 12, 4, 0.24, 6, 2.0, 2, 0.5, 15, 1, 0, 3, 5, 15.95,\n",
       "       27.3, 11891.1, 0.15, 95, 0.04, 660.62, 435.57, 0.25, 3, 6, 13, 0.2,\n",
       "       39, 56, 10, 14, 20, 82.35, 17, 0], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2=data1.values\n",
    "for i in range(1493):\n",
    "    if data2[i][36]==\"Y\":\n",
    "        data2[i][36]=1\n",
    "    else:\n",
    "        data2[i][36]=0\n",
    "data2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(data2).astype(float)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.  ,  1.  , 14.  , ..., 20.  , 82.35, 17.  ],\n",
       "       [ 7.  ,  2.  , 14.  , ..., 20.  , 82.35, 17.  ],\n",
       "       [ 7.  ,  0.  ,  4.  , ...,  8.  , 80.  ,  5.  ],\n",
       "       ...,\n",
       "       [ 3.  ,  6.  , 32.  , ..., 46.  , 92.86, 35.  ],\n",
       "       [ 5.  ,  3.  , 16.  , ..., 29.  , 88.89, 19.  ],\n",
       "       [ 7.  ,  0.  , 15.  , ..., 23.  , 76.19, 20.  ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,:36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=X[:,36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 1., 0.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X[:,0:36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2954, 36), (2954,))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
    "#os =  RandomOverSampler()\n",
    "X_res, y_res = SMOTE().fit_resample(X, y)\n",
    "X_res.shape,y_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2954, 36)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res.shape\n",
    "#X_res=X_res.reshape(898,21,1)\n",
    "#X_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "\n",
    "def show_accuracy(predictLabel,Label):\n",
    "    Label = np.ravel(Label).tolist()\n",
    "    predictLabel = predictLabel.tolist()\n",
    "    count = 0\n",
    "    for i in range(len(Label)):\n",
    "        if Label[i] == predictLabel[i]:\n",
    "            count += 1\n",
    "    return (round(count/len(Label),5))\n",
    "\n",
    "class node_generator(object):\n",
    "    def __init__(self, whiten = False):\n",
    "        self.Wlist = []\n",
    "        self.blist = []\n",
    "        self.function_num = 0\n",
    "        self.whiten = whiten\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1.0/(1 + np.exp(-x))\n",
    "\n",
    "    def relu(self, x):\n",
    "        return np.maximum(x, 0)\n",
    "\n",
    "    def tanh(self, x):\n",
    "        return (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x))\n",
    "\n",
    "    def linear(self, x):\n",
    "        return x\n",
    "\n",
    "    def orth(self, W):\n",
    "        \"\"\"\n",
    "        目前看来，这个函数应该配合下一个generator函数是生成权重的\n",
    "        \"\"\"\n",
    "        for i in range(0, W.shape[1]):\n",
    "            w = np.mat(W[:,i].copy()).T\n",
    "            w_sum = 0\n",
    "            for j in range(i):\n",
    "                wj = np.mat(W[:,j].copy()).T\n",
    "                w_sum += (w.T.dot(wj))[0,0]*wj\n",
    "            w -= w_sum\n",
    "            w = w/np.sqrt(w.T.dot(w))\n",
    "            W[:,i] = np.ravel(w)\n",
    "\n",
    "        return W\n",
    "\n",
    "    def generator(self, shape, times):\n",
    "        for i in range(times):\n",
    "            random.seed(i)\n",
    "            W = 2*np.random.random(size=shape)-1\n",
    "            if self.whiten == True:\n",
    "                W = self.orth(W)   # 只在增强层使用\n",
    "            b = 2*np.random.random() -1\n",
    "            yield (W, b)\n",
    "\n",
    "    def generator_nodes(self, data, times, batchsize, function_num):\n",
    "        # 按照bls的理论，mapping layer是输入乘以不同的权重加上不同的偏差之后得到的\n",
    "        # 若干组，所以，权重是一个列表，每一个元素可作为权重与输入相乘\n",
    "        self.Wlist = [elem[0] for elem in self.generator((data.shape[1], batchsize), times)]\n",
    "        self.blist = [elem[1] for elem in self.generator((data.shape[1], batchsize), times)]\n",
    "\n",
    "        self.function_num = {'linear':self.linear,\n",
    "                        'sigmoid': self.sigmoid,\n",
    "                        'tanh':self.tanh,\n",
    "                        'relu':self.relu }[function_num]  # 激活函数供不同的层选择\n",
    "        # 下面就是先得到一组mapping nodes，再不断叠加，得到len(Wlist)组mapping nodes\n",
    "        nodes = self.function_num(data.dot(self.Wlist[0]) + self.blist[0])\n",
    "        for i in range(1, len(self.Wlist)):\n",
    "            nodes = np.column_stack((nodes, self.function_num(data.dot(self.Wlist[i])+self.blist[i])))\n",
    "        return nodes\n",
    "\n",
    "    def transform(self,testdata):\n",
    "        testnodes = self.function_num(testdata.dot(self.Wlist[0])+self.blist[0])\n",
    "        for i in range(1,len(self.Wlist)):\n",
    "            testnodes = np.column_stack((testnodes, self.function_num(testdata.dot(self.Wlist[i])+self.blist[i])))\n",
    "        return testnodes\n",
    "\n",
    "class scaler:\n",
    "    def __init__(self):\n",
    "        self._mean = 0\n",
    "        self._std = 0\n",
    "    \n",
    "    def fit_transform(self,traindata):\n",
    "        self._mean = traindata.mean(axis = 0)\n",
    "        self._std = traindata.std(axis = 0)\n",
    "        return (traindata-self._mean)/(self._std+0.001)\n",
    "    \n",
    "    def transform(self,testdata):\n",
    "        return (testdata-self._mean)/(self._std+0.001)\n",
    "\n",
    "class broadnet:\n",
    "    def __init__(self, \n",
    "                 maptimes = 10, \n",
    "                 enhencetimes = 10,\n",
    "                 map_function = 'linear',\n",
    "                 enhence_function = 'linear',\n",
    "                 batchsize = 'auto', \n",
    "                 reg = 0.001):\n",
    "        \n",
    "        self._maptimes = maptimes\n",
    "        self._enhencetimes = enhencetimes\n",
    "        self._batchsize = batchsize\n",
    "        self._reg = reg\n",
    "        self._map_function = map_function\n",
    "        self._enhence_function = enhence_function\n",
    "        \n",
    "        self.W = 0\n",
    "        self.pesuedoinverse = 0\n",
    "        self.normalscaler = scaler()\n",
    "        self.onehotencoder = preprocessing.OneHotEncoder(sparse = False)\n",
    "        self.mapping_generator = node_generator()\n",
    "        self.enhence_generator = node_generator(whiten = True)\n",
    "\n",
    "    def fit(self,data,label,weight):\n",
    "        if self._batchsize == 'auto':\n",
    "            self._batchsize = data.shape[1]\n",
    "        data = self.normalscaler.fit_transform(data)\n",
    "        label = self.onehotencoder.fit_transform(np.mat(label).T)\n",
    "        \n",
    "        mappingdata = self.mapping_generator.generator_nodes(data,self._maptimes,self._batchsize,self._map_function)\n",
    "        enhencedata = self.enhence_generator.generator_nodes(mappingdata,self._enhencetimes,self._batchsize,self._enhence_function)\n",
    "        \n",
    "        #print('number of mapping nodes {0}, number of enhence nodes {1}'.format(mappingdata.shape[1],enhencedata.shape[1]))\n",
    "        #print('mapping nodes maxvalue {0} minvalue {1} '.format(round(np.max(mappingdata),5),round(np.min(mappingdata),5)))\n",
    "        #print('enhence nodes maxvalue {0} minvalue {1} '.format(round(np.max(enhencedata),5),round(np.min(enhencedata),5)))\n",
    "        \n",
    "        inputdata = np.column_stack((mappingdata,enhencedata))\n",
    "        pesuedoinverse = self.pinv(inputdata,self._reg,weight)\n",
    "        self.W =  pesuedoinverse.dot(label)\n",
    "        \n",
    "        #print('W:', self.W)\n",
    "        #print('W:', self.W.shape)  \n",
    "    \n",
    "    #改写伪逆矩阵算法，将权重输入\n",
    "    def pinv(self,A,reg,weight):\n",
    "        return np.mat(reg*np.eye(A.shape[1])+A.T.dot(weight).dot(A)).I.dot(A.T).dot(weight)\n",
    "    \n",
    "    def decode(self,Y_onehot):\n",
    "        Y = []\n",
    "        for i in range(Y_onehot.shape[0]):\n",
    "            lis = np.ravel(Y_onehot[i,:]).tolist()\n",
    "            Y.append(lis.index(max(lis)))\n",
    "        return np.array(Y)\n",
    "    \n",
    "    def accuracy(self,predictlabel,label):\n",
    "        label = np.ravel(label).tolist()\n",
    "        predictlabel = predictlabel.tolist()\n",
    "        count = 0\n",
    "        for i in range(len(label)):\n",
    "            if label[i] == predictlabel[i]:\n",
    "                count += 1\n",
    "        return (round(count/len(label),5))\n",
    "        \n",
    "    def predict(self,testdata):\n",
    "        testdata = self.normalscaler.transform(testdata)\n",
    "        test_mappingdata = self.mapping_generator.transform(testdata)\n",
    "        test_enhencedata = self.enhence_generator.transform(test_mappingdata)\n",
    "        \n",
    "        test_inputdata = np.column_stack((test_mappingdata,test_enhencedata)) \n",
    "        #print('*predictlabel shape:',self.decode(test_inputdata.dot(self.W)).shape)\n",
    "        #print('*predictlabel:', self.decode(test_inputdata.dot(self.W)))\n",
    "        #print('*accuracy:',show_accuracy(self.decode(test_inputdata.dot(self.W)),testlabel))\n",
    "        return self.decode(test_inputdata.dot(self.W))\n",
    "    \n",
    "    def addWeight(self,trainlabel):\n",
    "        #对BLS设置加权，按照训练集中的label比例进行权重设置\n",
    "        #求训练数据集中label为1的个数\n",
    "        count=0\n",
    "        for z in range(len(trainlabel)):\n",
    "            #print ('个数 %d ' %z)\n",
    "            #print('k_train_label:', k_train_label[z])\n",
    "            if trainlabel[z]==1:\n",
    "                count=count+1\n",
    "        #print ('label为1的个数 %d ' %j)\n",
    "        #print(count)\n",
    "        #print(k_train_label.shape)\n",
    "        #print(len(k_train_label))\n",
    "        #权重设置 \n",
    "        weight = np.zeros((len(trainlabel),len(trainlabel)))\n",
    "        for i in range(len(trainlabel)):\n",
    "            if trainlabel[i]==1:\n",
    "                #weight[i,i]=0.618/count\n",
    "                weight[i,i]=2*(len(trainlabel)-count)/len(trainlabel)\n",
    "            else:\n",
    "                #weight[i,i]=1/(len(k_train_label)-count)\n",
    "                weight[i,i]=2*count/len(trainlabel)\n",
    "        #print('Weight:', weight)\n",
    "        return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将数据集划分为训练集和测试集\n",
    "traindata,testdata,trainlabel,testlabel = train_test_split(X_res,y_res,test_size=0.25,random_state = 0)\n",
    "#print(traindata.shape,trainlabel.shape,testdata.shape,testlabel.shape)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2)\n",
    "#y_train = np_utils.to_categorical(y_train)\n",
    "#y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maptiems:15\tenhancetimes:15\tk_average_acc:0.98962\tk_average_f1:0.98961\tk_average_auc:0.98941\tk_average_recall:0.98962\tk_average_mcc:0.97944\tk_average_Gm:0.98941\t\n",
      "maptiems:15\tenhancetimes:20\tk_average_acc:0.98962\tk_average_f1:0.98961\tk_average_auc:0.98941\tk_average_recall:0.98962\tk_average_mcc:0.97944\tk_average_Gm:0.98941\t\n",
      "maptiems:15\tenhancetimes:25\tk_average_acc:0.99007\tk_average_f1:0.99006\tk_average_auc:0.98987\tk_average_recall:0.99007\tk_average_mcc:0.98032\tk_average_Gm:0.98987\t\n",
      "maptiems:15\tenhancetimes:30\tk_average_acc:0.99029\tk_average_f1:0.99029\tk_average_auc:0.9901\tk_average_recall:0.99029\tk_average_mcc:0.98077\tk_average_Gm:0.9901\t\n",
      "maptiems:15\tenhancetimes:35\tk_average_acc:0.99025\tk_average_f1:0.99024\tk_average_auc:0.99006\tk_average_recall:0.99025\tk_average_mcc:0.98068\tk_average_Gm:0.99006\t\n",
      "maptiems:20\tenhancetimes:15\tk_average_acc:0.98962\tk_average_f1:0.98961\tk_average_auc:0.98941\tk_average_recall:0.98962\tk_average_mcc:0.97944\tk_average_Gm:0.98941\t\n",
      "maptiems:20\tenhancetimes:20\tk_average_acc:0.99029\tk_average_f1:0.99029\tk_average_auc:0.9901\tk_average_recall:0.99029\tk_average_mcc:0.98077\tk_average_Gm:0.9901\t\n",
      "maptiems:20\tenhancetimes:25\tk_average_acc:0.99037\tk_average_f1:0.99036\tk_average_auc:0.99018\tk_average_recall:0.99037\tk_average_mcc:0.98092\tk_average_Gm:0.99018\t\n",
      "maptiems:20\tenhancetimes:30\tk_average_acc:0.99052\tk_average_f1:0.99052\tk_average_auc:0.99034\tk_average_recall:0.99052\tk_average_mcc:0.98121\tk_average_Gm:0.99034\t\n",
      "maptiems:20\tenhancetimes:35\tk_average_acc:0.99025\tk_average_f1:0.99024\tk_average_auc:0.99006\tk_average_recall:0.99025\tk_average_mcc:0.98068\tk_average_Gm:0.99006\t\n",
      "maptiems:25\tenhancetimes:15\tk_average_acc:0.99097\tk_average_f1:0.99097\tk_average_auc:0.99081\tk_average_recall:0.99097\tk_average_mcc:0.98209\tk_average_Gm:0.99081\t\n",
      "maptiems:25\tenhancetimes:20\tk_average_acc:0.99142\tk_average_f1:0.99142\tk_average_auc:0.99127\tk_average_recall:0.99142\tk_average_mcc:0.98299\tk_average_Gm:0.99127\t\n",
      "maptiems:25\tenhancetimes:25\tk_average_acc:0.99097\tk_average_f1:0.99097\tk_average_auc:0.99081\tk_average_recall:0.99097\tk_average_mcc:0.9821\tk_average_Gm:0.99081\t\n",
      "maptiems:25\tenhancetimes:30\tk_average_acc:0.99063\tk_average_f1:0.99063\tk_average_auc:0.99046\tk_average_recall:0.99063\tk_average_mcc:0.98143\tk_average_Gm:0.99046\t\n",
      "maptiems:25\tenhancetimes:35\tk_average_acc:0.99061\tk_average_f1:0.99061\tk_average_auc:0.99043\tk_average_recall:0.99061\tk_average_mcc:0.98139\tk_average_Gm:0.99043\t\n",
      "maptiems:30\tenhancetimes:15\tk_average_acc:0.99007\tk_average_f1:0.99006\tk_average_auc:0.98988\tk_average_recall:0.99007\tk_average_mcc:0.98032\tk_average_Gm:0.98988\t\n",
      "maptiems:30\tenhancetimes:20\tk_average_acc:0.98916\tk_average_f1:0.98916\tk_average_auc:0.98896\tk_average_recall:0.98916\tk_average_mcc:0.97855\tk_average_Gm:0.98896\t\n",
      "maptiems:30\tenhancetimes:25\tk_average_acc:0.98886\tk_average_f1:0.98886\tk_average_auc:0.98865\tk_average_recall:0.98886\tk_average_mcc:0.97797\tk_average_Gm:0.98865\t\n",
      "maptiems:30\tenhancetimes:30\tk_average_acc:0.98928\tk_average_f1:0.98927\tk_average_auc:0.98907\tk_average_recall:0.98928\tk_average_mcc:0.97878\tk_average_Gm:0.98907\t\n",
      "maptiems:30\tenhancetimes:35\tk_average_acc:0.98953\tk_average_f1:0.98952\tk_average_auc:0.98932\tk_average_recall:0.98953\tk_average_mcc:0.97927\tk_average_Gm:0.98932\t\n",
      "maptiems:35\tenhancetimes:15\tk_average_acc:0.99187\tk_average_f1:0.99187\tk_average_auc:0.99173\tk_average_recall:0.99187\tk_average_mcc:0.98387\tk_average_Gm:0.99173\t\n",
      "maptiems:35\tenhancetimes:20\tk_average_acc:0.99165\tk_average_f1:0.99164\tk_average_auc:0.99149\tk_average_recall:0.99165\tk_average_mcc:0.98343\tk_average_Gm:0.99149\t\n",
      "maptiems:35\tenhancetimes:25\tk_average_acc:0.99157\tk_average_f1:0.99157\tk_average_auc:0.99141\tk_average_recall:0.99157\tk_average_mcc:0.98329\tk_average_Gm:0.99141\t\n",
      "maptiems:35\tenhancetimes:30\tk_average_acc:0.99131\tk_average_f1:0.99131\tk_average_auc:0.99114\tk_average_recall:0.99131\tk_average_mcc:0.98277\tk_average_Gm:0.99114\t\n",
      "maptiems:35\tenhancetimes:35\tk_average_acc:0.99097\tk_average_f1:0.99097\tk_average_auc:0.9908\tk_average_recall:0.99097\tk_average_mcc:0.98211\tk_average_Gm:0.9908\t\n"
     ]
    }
   ],
   "source": [
    "k_acc_list, k_f1_list, k_auc_list, k_recall_list, k_mcc_list, k_Gm_list=[],[],[],[],[],[]\n",
    "#这里设置shuffle设置为ture就是打乱顺序在分配\n",
    "kf = KFold(n_splits=3,shuffle=True,random_state=42)\n",
    "for map_times in np.arange(15,36,5):\n",
    "    acc_list_tmp, f1_list_tmp, auc_list_tmp, recall_list_tmp, mcc_list_tmp,Gm_list_tmp=[],[],[],[],[],[]\n",
    "    for enhance_times in np.arange(15, 36,5):\n",
    "        for k, (train, test) in enumerate(kf.split(traindata, trainlabel)):\n",
    "            # kf.split输出的是索引，所以由索引获取交叉后的训练集和测试集及标签\n",
    "            k_train_data,k_train_label = traindata[train], trainlabel[train]\n",
    "            k_test_data,k_test_label = traindata[test], trainlabel[test]           \n",
    "\n",
    "            bls = broadnet(maptimes = map_times, \n",
    "                       enhencetimes = enhance_times,\n",
    "                       map_function = 'relu',\n",
    "                       enhence_function = 'relu',\n",
    "                       batchsize =100,\n",
    "                       reg = 0.001)\n",
    "\n",
    "            #根据训练数据设置权重\n",
    "            weight=bls.addWeight(k_train_label)\n",
    "\n",
    "            #训练\n",
    "            starttime = datetime.datetime.now()\n",
    "            bls.fit(k_train_data,k_train_label,weight)\n",
    "            endtime = datetime.datetime.now()\n",
    "            #print('the training time of BLS is {0} seconds'.format((endtime - starttime).total_seconds()))\n",
    "\n",
    "            #print('k_test_label:', k_test_label)\n",
    "            #预测\n",
    "            k_predict_label = bls.predict(k_test_data)\n",
    "            #print('k_predict_label:', k_predict_label)\n",
    "\n",
    "            #评价指标计算\n",
    "            acc=accuracy_score(k_test_label,k_predict_label,normalize=True)\n",
    "            fmeasure=f1_score(k_test_label,k_predict_label, average='weighted', labels=np.unique(k_test_label))\n",
    "            try:\n",
    "                auc=roc_auc_score(k_test_label,k_predict_label, average='macro', sample_weight=None)\n",
    "            except ValueError:\n",
    "                pass\n",
    "            recall=recall_score(k_test_label, k_predict_label, average='weighted')\n",
    "            MCC=matthews_corrcoef(k_test_label,k_predict_label)\n",
    "            Gmeasure=geometric_mean_score(k_test_label,k_predict_label, average='weighted')\n",
    "\n",
    "            #将此次的十折交叉验证的结果 (10个)保存到pi_list_tmp中\n",
    "            acc_list_tmp.append(acc)\n",
    "            f1_list_tmp.append(fmeasure)\n",
    "            auc_list_tmp.append(auc)\n",
    "            recall_list_tmp.append(recall)\n",
    "            mcc_list_tmp.append(MCC)\n",
    "            Gm_list_tmp.append(Gmeasure)\n",
    "\n",
    "        #求平均保存到k_acc_list中   \n",
    "        k_average_acc=np.mean(acc_list_tmp)\n",
    "        k_average_acc=round(k_average_acc,5)\n",
    "        k_acc_list.append(k_average_acc)\n",
    "\n",
    "        #求平均保存到k_f1_list中   \n",
    "        k_average_f1=np.mean(f1_list_tmp)\n",
    "        k_average_f1=round(k_average_f1,5)\n",
    "        k_f1_list.append(k_average_f1)\n",
    "\n",
    "        #求平均保存到k_auc_list中   \n",
    "        k_average_auc=np.mean(auc_list_tmp)\n",
    "        k_average_auc=round(k_average_auc,5)\n",
    "        k_auc_list.append(k_average_auc)\n",
    "        \n",
    "        #求平均保存到k_recall_list中   \n",
    "        k_average_recall=np.mean(recall_list_tmp)\n",
    "        k_average_recall=round(k_average_recall,5)\n",
    "        k_recall_list.append(k_average_recall)\n",
    "\n",
    "\n",
    "        #求平均保存到k_mcc_list中   \n",
    "        k_average_mcc=np.mean(mcc_list_tmp)\n",
    "        k_average_mcc=round(k_average_mcc,5)\n",
    "        k_mcc_list.append(k_average_mcc)\n",
    "\n",
    "        #求平均保存到k_Gm_list中   \n",
    "        k_average_Gm=np.mean(Gm_list_tmp)\n",
    "        k_average_Gm=round(k_average_Gm,5)\n",
    "        k_Gm_list.append(k_average_Gm)\n",
    "        print(f'maptiems:{map_times}\\tenhancetimes:{enhance_times}\\tk_average_acc:{k_average_acc}\\tk_average_f1:{k_average_f1}\\tk_average_auc:{k_average_auc}\\tk_average_recall:{k_average_recall}\\tk_average_mcc:{k_average_mcc}\\tk_average_Gm:{k_average_Gm}\\t')\n",
    "\n",
    "k_acc_array=np.array(k_acc_list)\n",
    "k_acc_array=k_acc_array.reshape(5,5)\n",
    "# 一维最大值索引\n",
    "#idx_max_ravel = np.argmax(k_acc_array)\n",
    "# true索引\n",
    "#idx_max = np.unravel_index(idx_max_ravel, k_acc_array.shape)\n",
    "#print('max times:',idx_max)\n",
    "\n",
    "k_f1_array=np.array(k_f1_list)\n",
    "k_f1_array=k_f1_array.reshape(5,5)\n",
    "\n",
    "k_auc_array=np.array(k_auc_list)\n",
    "k_auc_array=k_auc_array.reshape(5,5)\n",
    "\n",
    "k_recall_array=np.array(k_recall_list)\n",
    "k_recall_array=k_recall_array.reshape(5,5)\n",
    "\n",
    "k_mcc_array=np.array(k_mcc_list)\n",
    "k_mcc_array=k_mcc_array.reshape(5,5)\n",
    "\n",
    "k_Gm_array=np.array(k_Gm_list)\n",
    "k_Gm_array=k_Gm_array.reshape(5,5)\n",
    "\n",
    "sio.savemat('./data_remember/0.75WBLS_Smote_PC2_MEbest.mat',{'acc':k_acc_array,'f1':k_f1_array,'auc':k_auc_array,'recall':k_recall_array,'mcc':k_mcc_array,'Gm':k_Gm_array})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf01",
   "language": "python",
   "name": "tf01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
