{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,recall_score,precision_score,f1_score,roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOC_BLANK numeric</th>\n",
       "      <th>BRANCH_COUNT numeric</th>\n",
       "      <th>CALL_PAIRS numeric</th>\n",
       "      <th>LOC_CODE_AND_COMMENT numeric</th>\n",
       "      <th>LOC_COMMENTS numeric</th>\n",
       "      <th>CONDITION_COUNT numeric</th>\n",
       "      <th>CYCLOMATIC_COMPLEXITY numeric</th>\n",
       "      <th>CYCLOMATIC_DENSITY numeric</th>\n",
       "      <th>DECISION_COUNT numeric</th>\n",
       "      <th>DESIGN_COMPLEXITY numeric</th>\n",
       "      <th>...</th>\n",
       "      <th>NODE_COUNT numeric</th>\n",
       "      <th>NORMALIZED_CYLOMATIC_COMPLEXITY numeric</th>\n",
       "      <th>NUM_OPERANDS numeric</th>\n",
       "      <th>NUM_OPERATORS numeric</th>\n",
       "      <th>NUM_UNIQUE_OPERANDS numeric</th>\n",
       "      <th>NUM_UNIQUE_OPERATORS numeric</th>\n",
       "      <th>NUMBER_OF_LINES numeric</th>\n",
       "      <th>PERCENT_COMMENTS numeric</th>\n",
       "      <th>LOC_TOTAL numeric</th>\n",
       "      <th>Defective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>0.16</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>0.12</td>\n",
       "      <td>69</td>\n",
       "      <td>95</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>76</td>\n",
       "      <td>18.18</td>\n",
       "      <td>55</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.19</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>6.25</td>\n",
       "      <td>16</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0.08</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0.02</td>\n",
       "      <td>188</td>\n",
       "      <td>252</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>183</td>\n",
       "      <td>68.82</td>\n",
       "      <td>53</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.60</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.43</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.11</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>28.57</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LOC_BLANK numeric   BRANCH_COUNT numeric   CALL_PAIRS numeric  \\\n",
       "0                  8                     17                   12   \n",
       "1                  2                      5                    3   \n",
       "2                 11                      7                    2   \n",
       "3                  0                      5                    1   \n",
       "4                  0                      1                    2   \n",
       "\n",
       "    LOC_CODE_AND_COMMENT numeric   LOC_COMMENTS numeric  \\\n",
       "0                              1                     11   \n",
       "1                              1                      0   \n",
       "2                              0                    117   \n",
       "3                              0                      0   \n",
       "4                              0                      2   \n",
       "\n",
       "    CONDITION_COUNT numeric   CYCLOMATIC_COMPLEXITY numeric  \\\n",
       "0                        30                               9   \n",
       "1                         8                               3   \n",
       "2                        12                               4   \n",
       "3                         8                               3   \n",
       "4                         0                               1   \n",
       "\n",
       "    CYCLOMATIC_DENSITY numeric   DECISION_COUNT numeric  \\\n",
       "0                         0.16                       14   \n",
       "1                         0.19                        4   \n",
       "2                         0.08                        6   \n",
       "3                         0.60                        4   \n",
       "4                         0.20                        0   \n",
       "\n",
       "    DESIGN_COMPLEXITY numeric  ...   NODE_COUNT numeric  \\\n",
       "0                           8  ...                   38   \n",
       "1                           3  ...                   14   \n",
       "2                           4  ...                   34   \n",
       "3                           2  ...                    8   \n",
       "4                           1  ...                    4   \n",
       "\n",
       "    NORMALIZED_CYLOMATIC_COMPLEXITY numeric   NUM_OPERANDS numeric  \\\n",
       "0                                      0.12                     69   \n",
       "1                                      0.15                     26   \n",
       "2                                      0.02                    188   \n",
       "3                                      0.43                      5   \n",
       "4                                      0.11                     10   \n",
       "\n",
       "    NUM_OPERATORS numeric   NUM_UNIQUE_OPERANDS numeric  \\\n",
       "0                      95                            33   \n",
       "1                      31                            15   \n",
       "2                     252                            18   \n",
       "3                       8                             4   \n",
       "4                      18                             4   \n",
       "\n",
       "    NUM_UNIQUE_OPERATORS numeric   NUMBER_OF_LINES numeric  \\\n",
       "0                             20                        76   \n",
       "1                             10                        20   \n",
       "2                             23                       183   \n",
       "3                              6                         7   \n",
       "4                              9                         9   \n",
       "\n",
       "    PERCENT_COMMENTS numeric   LOC_TOTAL numeric   Defective  \n",
       "0                      18.18                  55           N  \n",
       "1                       6.25                  16           N  \n",
       "2                      68.82                  53           N  \n",
       "3                       0.00                   5           N  \n",
       "4                      28.57                   5           N  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv(\"../../dataset/NASA/MC1.csv\")\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOC_BLANK numeric</th>\n",
       "      <th>BRANCH_COUNT numeric</th>\n",
       "      <th>CALL_PAIRS numeric</th>\n",
       "      <th>LOC_CODE_AND_COMMENT numeric</th>\n",
       "      <th>LOC_COMMENTS numeric</th>\n",
       "      <th>CONDITION_COUNT numeric</th>\n",
       "      <th>CYCLOMATIC_COMPLEXITY numeric</th>\n",
       "      <th>CYCLOMATIC_DENSITY numeric</th>\n",
       "      <th>DECISION_COUNT numeric</th>\n",
       "      <th>DESIGN_COMPLEXITY numeric</th>\n",
       "      <th>...</th>\n",
       "      <th>MULTIPLE_CONDITION_COUNT numeric</th>\n",
       "      <th>NODE_COUNT numeric</th>\n",
       "      <th>NORMALIZED_CYLOMATIC_COMPLEXITY numeric</th>\n",
       "      <th>NUM_OPERANDS numeric</th>\n",
       "      <th>NUM_OPERATORS numeric</th>\n",
       "      <th>NUM_UNIQUE_OPERANDS numeric</th>\n",
       "      <th>NUM_UNIQUE_OPERATORS numeric</th>\n",
       "      <th>NUMBER_OF_LINES numeric</th>\n",
       "      <th>PERCENT_COMMENTS numeric</th>\n",
       "      <th>LOC_TOTAL numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1988.000000</td>\n",
       "      <td>1988.000000</td>\n",
       "      <td>1988.000000</td>\n",
       "      <td>1988.000000</td>\n",
       "      <td>1988.000000</td>\n",
       "      <td>1988.000000</td>\n",
       "      <td>1988.000000</td>\n",
       "      <td>1988.000000</td>\n",
       "      <td>1988.000000</td>\n",
       "      <td>1988.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1988.000000</td>\n",
       "      <td>1988.000000</td>\n",
       "      <td>1988.000000</td>\n",
       "      <td>1988.000000</td>\n",
       "      <td>1988.000000</td>\n",
       "      <td>1988.000000</td>\n",
       "      <td>1988.000000</td>\n",
       "      <td>1988.000000</td>\n",
       "      <td>1988.000000</td>\n",
       "      <td>1988.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.643360</td>\n",
       "      <td>7.304326</td>\n",
       "      <td>3.100604</td>\n",
       "      <td>2.051811</td>\n",
       "      <td>4.704728</td>\n",
       "      <td>10.530181</td>\n",
       "      <td>3.894869</td>\n",
       "      <td>0.293134</td>\n",
       "      <td>4.984909</td>\n",
       "      <td>2.827465</td>\n",
       "      <td>...</td>\n",
       "      <td>5.269115</td>\n",
       "      <td>16.336016</td>\n",
       "      <td>0.192641</td>\n",
       "      <td>42.314386</td>\n",
       "      <td>61.073944</td>\n",
       "      <td>15.045272</td>\n",
       "      <td>11.296278</td>\n",
       "      <td>33.105634</td>\n",
       "      <td>18.955619</td>\n",
       "      <td>20.887827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.251612</td>\n",
       "      <td>15.449528</td>\n",
       "      <td>4.474604</td>\n",
       "      <td>5.651232</td>\n",
       "      <td>12.056771</td>\n",
       "      <td>25.823967</td>\n",
       "      <td>7.955621</td>\n",
       "      <td>0.240868</td>\n",
       "      <td>12.521055</td>\n",
       "      <td>6.884109</td>\n",
       "      <td>...</td>\n",
       "      <td>12.918603</td>\n",
       "      <td>31.925851</td>\n",
       "      <td>0.217999</td>\n",
       "      <td>95.588313</td>\n",
       "      <td>130.981295</td>\n",
       "      <td>16.755561</td>\n",
       "      <td>7.454424</td>\n",
       "      <td>46.904468</td>\n",
       "      <td>20.922315</td>\n",
       "      <td>33.170678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>13.640000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>87.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>630.000000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>315.000000</td>\n",
       "      <td>739.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2279.000000</td>\n",
       "      <td>2948.000000</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>727.000000</td>\n",
       "      <td>95.760000</td>\n",
       "      <td>639.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LOC_BLANK numeric   BRANCH_COUNT numeric   CALL_PAIRS numeric  \\\n",
       "count        1988.000000            1988.000000          1988.000000   \n",
       "mean            4.643360               7.304326             3.100604   \n",
       "std             7.251612              15.449528             4.474604   \n",
       "min             0.000000               1.000000             0.000000   \n",
       "25%             0.000000               1.000000             1.000000   \n",
       "50%             2.000000               3.000000             2.000000   \n",
       "75%             6.000000               7.000000             4.000000   \n",
       "max            87.000000             351.000000            72.000000   \n",
       "\n",
       "        LOC_CODE_AND_COMMENT numeric   LOC_COMMENTS numeric  \\\n",
       "count                    1988.000000            1988.000000   \n",
       "mean                        2.051811               4.704728   \n",
       "std                         5.651232              12.056771   \n",
       "min                         0.000000               0.000000   \n",
       "25%                         0.000000               0.000000   \n",
       "50%                         0.000000               1.000000   \n",
       "75%                         2.000000               4.000000   \n",
       "max                        98.000000             117.000000   \n",
       "\n",
       "        CONDITION_COUNT numeric   CYCLOMATIC_COMPLEXITY numeric  \\\n",
       "count               1988.000000                     1988.000000   \n",
       "mean                  10.530181                        3.894869   \n",
       "std                   25.823967                        7.955621   \n",
       "min                    0.000000                        1.000000   \n",
       "25%                    0.000000                        1.000000   \n",
       "50%                    4.000000                        2.000000   \n",
       "75%                   12.000000                        4.000000   \n",
       "max                  630.000000                      192.000000   \n",
       "\n",
       "        CYCLOMATIC_DENSITY numeric   DECISION_COUNT numeric  \\\n",
       "count                  1988.000000              1988.000000   \n",
       "mean                      0.293134                 4.984909   \n",
       "std                       0.240868                12.521055   \n",
       "min                       0.000000                 0.000000   \n",
       "25%                       0.140000                 0.000000   \n",
       "50%                       0.230000                 2.000000   \n",
       "75%                       0.330000                 6.000000   \n",
       "max                       1.000000               312.000000   \n",
       "\n",
       "        DESIGN_COMPLEXITY numeric  ...   MULTIPLE_CONDITION_COUNT numeric  \\\n",
       "count                 1988.000000  ...                        1988.000000   \n",
       "mean                     2.827465  ...                           5.269115   \n",
       "std                      6.884109  ...                          12.918603   \n",
       "min                      1.000000  ...                           0.000000   \n",
       "25%                      1.000000  ...                           0.000000   \n",
       "50%                      1.000000  ...                           2.000000   \n",
       "75%                      3.000000  ...                           6.000000   \n",
       "max                    186.000000  ...                         315.000000   \n",
       "\n",
       "        NODE_COUNT numeric   NORMALIZED_CYLOMATIC_COMPLEXITY numeric  \\\n",
       "count          1988.000000                               1988.000000   \n",
       "mean             16.336016                                  0.192641   \n",
       "std              31.925851                                  0.217999   \n",
       "min               2.000000                                  0.000000   \n",
       "25%               4.000000                                  0.090000   \n",
       "50%               9.000000                                  0.140000   \n",
       "75%              18.000000                                  0.210000   \n",
       "max             739.000000                                  2.000000   \n",
       "\n",
       "        NUM_OPERANDS numeric   NUM_OPERATORS numeric  \\\n",
       "count            1988.000000             1988.000000   \n",
       "mean               42.314386               61.073944   \n",
       "std                95.588313              130.981295   \n",
       "min                 0.000000                0.000000   \n",
       "25%                 7.000000               12.000000   \n",
       "50%                19.000000               29.000000   \n",
       "75%                43.000000               63.000000   \n",
       "max              2279.000000             2948.000000   \n",
       "\n",
       "        NUM_UNIQUE_OPERANDS numeric   NUM_UNIQUE_OPERATORS numeric  \\\n",
       "count                   1988.000000                    1988.000000   \n",
       "mean                      15.045272                      11.296278   \n",
       "std                       16.755561                       7.454424   \n",
       "min                        0.000000                       0.000000   \n",
       "25%                        5.000000                       6.000000   \n",
       "50%                       11.000000                      10.000000   \n",
       "75%                       20.000000                      14.000000   \n",
       "max                      197.000000                     100.000000   \n",
       "\n",
       "        NUMBER_OF_LINES numeric   PERCENT_COMMENTS numeric   LOC_TOTAL numeric  \n",
       "count               1988.000000                1988.000000         1988.000000  \n",
       "mean                  33.105634                  18.955619           20.887827  \n",
       "std                   46.904468                  20.922315           33.170678  \n",
       "min                    1.000000                   0.000000            0.000000  \n",
       "25%                    9.000000                   0.000000            5.000000  \n",
       "50%                   19.000000                  13.640000           11.000000  \n",
       "75%                   37.000000                  32.500000           24.000000  \n",
       "max                  727.000000                  95.760000          639.000000  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1988, 39)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 5, 3, 1, 0, 8, 3, 0.19, 4, 3, 1, 15, 1, 0, 15, 0, 3, 1, 30.54,\n",
       "       8.67, 2294.06, 0.09, 57, 0.12, 127.45, 264.7, 0, 2, 4, 14, 0.15,\n",
       "       26, 31, 15, 10, 20, 6.25, 16, 0], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2=data1.values\n",
    "for i in range(1988):\n",
    "    if data2[i][38]==\"Y\":\n",
    "        data2[i][38]=1\n",
    "    else:\n",
    "        data2[i][38]=0\n",
    "data2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(data2).astype(float)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8.  ,  17.  ,  12.  , ...,  76.  ,  18.18,  55.  ],\n",
       "       [  2.  ,   5.  ,   3.  , ...,  20.  ,   6.25,  16.  ],\n",
       "       [ 11.  ,   7.  ,   2.  , ..., 183.  ,  68.82,  53.  ],\n",
       "       ...,\n",
       "       [ 17.  ,   1.  ,   3.  , ...,  31.  ,   0.  ,  11.  ],\n",
       "       [  0.  ,   1.  ,   2.  , ...,   2.  ,   0.  ,   0.  ],\n",
       "       [  5.  ,   3.  ,   1.  , ...,  17.  ,  20.  ,   8.  ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,:38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=X[:,38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X[:,0:38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3884, 38), (3884,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
    "#os =  RandomOverSampler()\n",
    "X_res, y_res = SMOTE().fit_resample(X, y)\n",
    "X_res.shape,y_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3884, 38)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res.shape\n",
    "#X_res=X_res.reshape(898,21,1)\n",
    "#X_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "\n",
    "def show_accuracy(predictLabel,Label):\n",
    "    Label = np.ravel(Label).tolist()\n",
    "    predictLabel = predictLabel.tolist()\n",
    "    count = 0\n",
    "    for i in range(len(Label)):\n",
    "        if Label[i] == predictLabel[i]:\n",
    "            count += 1\n",
    "    return (round(count/len(Label),5))\n",
    "\n",
    "class node_generator(object):\n",
    "    def __init__(self, whiten = False):\n",
    "        self.Wlist = []\n",
    "        self.blist = []\n",
    "        self.function_num = 0\n",
    "        self.whiten = whiten\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1.0/(1 + np.exp(-x))\n",
    "\n",
    "    def relu(self, x):\n",
    "        return np.maximum(x, 0)\n",
    "\n",
    "    def tanh(self, x):\n",
    "        return (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x))\n",
    "\n",
    "    def linear(self, x):\n",
    "        return x\n",
    "\n",
    "    def orth(self, W):\n",
    "        \"\"\"\n",
    "        目前看来，这个函数应该配合下一个generator函数是生成权重的\n",
    "        \"\"\"\n",
    "        for i in range(0, W.shape[1]):\n",
    "            w = np.mat(W[:,i].copy()).T\n",
    "            w_sum = 0\n",
    "            for j in range(i):\n",
    "                wj = np.mat(W[:,j].copy()).T\n",
    "                w_sum += (w.T.dot(wj))[0,0]*wj\n",
    "            w -= w_sum\n",
    "            w = w/np.sqrt(w.T.dot(w))\n",
    "            W[:,i] = np.ravel(w)\n",
    "\n",
    "        return W\n",
    "\n",
    "    def generator(self, shape, times):\n",
    "        for i in range(times):\n",
    "            random.seed(i)\n",
    "            W = 2*np.random.random(size=shape)-1\n",
    "            if self.whiten == True:\n",
    "                W = self.orth(W)   # 只在增强层使用\n",
    "            b = 2*np.random.random() -1\n",
    "            yield (W, b)\n",
    "\n",
    "    def generator_nodes(self, data, times, batchsize, function_num):\n",
    "        # 按照bls的理论，mapping layer是输入乘以不同的权重加上不同的偏差之后得到的\n",
    "        # 若干组，所以，权重是一个列表，每一个元素可作为权重与输入相乘\n",
    "        self.Wlist = [elem[0] for elem in self.generator((data.shape[1], batchsize), times)]\n",
    "        self.blist = [elem[1] for elem in self.generator((data.shape[1], batchsize), times)]\n",
    "\n",
    "        self.function_num = {'linear':self.linear,\n",
    "                        'sigmoid': self.sigmoid,\n",
    "                        'tanh':self.tanh,\n",
    "                        'relu':self.relu }[function_num]  # 激活函数供不同的层选择\n",
    "        # 下面就是先得到一组mapping nodes，再不断叠加，得到len(Wlist)组mapping nodes\n",
    "        nodes = self.function_num(data.dot(self.Wlist[0]) + self.blist[0])\n",
    "        for i in range(1, len(self.Wlist)):\n",
    "            nodes = np.column_stack((nodes, self.function_num(data.dot(self.Wlist[i])+self.blist[i])))\n",
    "        return nodes\n",
    "\n",
    "    def transform(self,testdata):\n",
    "        testnodes = self.function_num(testdata.dot(self.Wlist[0])+self.blist[0])\n",
    "        for i in range(1,len(self.Wlist)):\n",
    "            testnodes = np.column_stack((testnodes, self.function_num(testdata.dot(self.Wlist[i])+self.blist[i])))\n",
    "        return testnodes\n",
    "\n",
    "class scaler:\n",
    "    def __init__(self):\n",
    "        self._mean = 0\n",
    "        self._std = 0\n",
    "    \n",
    "    def fit_transform(self,traindata):\n",
    "        self._mean = traindata.mean(axis = 0)\n",
    "        self._std = traindata.std(axis = 0)\n",
    "        return (traindata-self._mean)/(self._std+0.001)\n",
    "    \n",
    "    def transform(self,testdata):\n",
    "        return (testdata-self._mean)/(self._std+0.001)\n",
    "\n",
    "class broadnet:\n",
    "    def __init__(self, \n",
    "                 maptimes = 10, \n",
    "                 enhencetimes = 10,\n",
    "                 map_function = 'linear',\n",
    "                 enhence_function = 'linear',\n",
    "                 batchsize = 'auto', \n",
    "                 reg = 0.001):\n",
    "        \n",
    "        self._maptimes = maptimes\n",
    "        self._enhencetimes = enhencetimes\n",
    "        self._batchsize = batchsize\n",
    "        self._reg = reg\n",
    "        self._map_function = map_function\n",
    "        self._enhence_function = enhence_function\n",
    "        \n",
    "        self.W = 0\n",
    "        self.pesuedoinverse = 0\n",
    "        self.normalscaler = scaler()\n",
    "        self.onehotencoder = preprocessing.OneHotEncoder(sparse = False)\n",
    "        self.mapping_generator = node_generator()\n",
    "        self.enhence_generator = node_generator(whiten = True)\n",
    "\n",
    "    def fit(self,data,label,weight):\n",
    "        if self._batchsize == 'auto':\n",
    "            self._batchsize = data.shape[1]\n",
    "        data = self.normalscaler.fit_transform(data)\n",
    "        label = self.onehotencoder.fit_transform(np.mat(label).T)\n",
    "        \n",
    "        mappingdata = self.mapping_generator.generator_nodes(data,self._maptimes,self._batchsize,self._map_function)\n",
    "        enhencedata = self.enhence_generator.generator_nodes(mappingdata,self._enhencetimes,self._batchsize,self._enhence_function)\n",
    "        \n",
    "        #print('number of mapping nodes {0}, number of enhence nodes {1}'.format(mappingdata.shape[1],enhencedata.shape[1]))\n",
    "        #print('mapping nodes maxvalue {0} minvalue {1} '.format(round(np.max(mappingdata),5),round(np.min(mappingdata),5)))\n",
    "        #print('enhence nodes maxvalue {0} minvalue {1} '.format(round(np.max(enhencedata),5),round(np.min(enhencedata),5)))\n",
    "        \n",
    "        inputdata = np.column_stack((mappingdata,enhencedata))\n",
    "        pesuedoinverse = self.pinv(inputdata,self._reg,weight)\n",
    "        self.W =  pesuedoinverse.dot(label)\n",
    "        \n",
    "        #print('W:', self.W)\n",
    "        #print('W:', self.W.shape)  \n",
    "    \n",
    "    #改写伪逆矩阵算法，将权重输入\n",
    "    def pinv(self,A,reg,weight):\n",
    "        return np.mat(reg*np.eye(A.shape[1])+A.T.dot(weight).dot(A)).I.dot(A.T).dot(weight)\n",
    "    \n",
    "    def decode(self,Y_onehot):\n",
    "        Y = []\n",
    "        for i in range(Y_onehot.shape[0]):\n",
    "            lis = np.ravel(Y_onehot[i,:]).tolist()\n",
    "            Y.append(lis.index(max(lis)))\n",
    "        return np.array(Y)\n",
    "    \n",
    "    def accuracy(self,predictlabel,label):\n",
    "        label = np.ravel(label).tolist()\n",
    "        predictlabel = predictlabel.tolist()\n",
    "        count = 0\n",
    "        for i in range(len(label)):\n",
    "            if label[i] == predictlabel[i]:\n",
    "                count += 1\n",
    "        return (round(count/len(label),5))\n",
    "        \n",
    "    def predict(self,testdata):\n",
    "        testdata = self.normalscaler.transform(testdata)\n",
    "        test_mappingdata = self.mapping_generator.transform(testdata)\n",
    "        test_enhencedata = self.enhence_generator.transform(test_mappingdata)\n",
    "        \n",
    "        test_inputdata = np.column_stack((test_mappingdata,test_enhencedata)) \n",
    "        #print('*predictlabel shape:',self.decode(test_inputdata.dot(self.W)).shape)\n",
    "        #print('*predictlabel:', self.decode(test_inputdata.dot(self.W)))\n",
    "        #print('*accuracy:',show_accuracy(self.decode(test_inputdata.dot(self.W)),testlabel))\n",
    "        return self.decode(test_inputdata.dot(self.W))\n",
    "    \n",
    "    def addWeight(self,trainlabel):\n",
    "        #对BLS设置加权，按照训练集中的label比例进行权重设置\n",
    "        #求训练数据集中label为1的个数\n",
    "        count=0\n",
    "        for z in range(len(trainlabel)):\n",
    "            #print ('个数 %d ' %z)\n",
    "            #print('k_train_label:', k_train_label[z])\n",
    "            if trainlabel[z]==1:\n",
    "                count=count+1\n",
    "        #print ('label为1的个数 %d ' %j)\n",
    "        #print(count)\n",
    "        #print(k_train_label.shape)\n",
    "        #print(len(k_train_label))\n",
    "        #权重设置 \n",
    "        weight = np.zeros((len(trainlabel),len(trainlabel)))\n",
    "        for i in range(len(trainlabel)):\n",
    "            if trainlabel[i]==1:\n",
    "                #weight[i,i]=0.618/count\n",
    "                weight[i,i]=2*(len(trainlabel)-count)/len(trainlabel)\n",
    "            else:\n",
    "                #weight[i,i]=1/(len(k_train_label)-count)\n",
    "                weight[i,i]=2*count/len(trainlabel)\n",
    "        #print('Weight:', weight)\n",
    "        return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将数据集划分为训练集和测试集\n",
    "traindata,testdata,trainlabel,testlabel = train_test_split(X_res,y_res,test_size=0.25,random_state = 0)\n",
    "#print(traindata.shape,trainlabel.shape,testdata.shape,testlabel.shape)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2)\n",
    "#y_train = np_utils.to_categorical(y_train)\n",
    "#y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maptiems:15\tenhancetimes:15\tk_average_acc:0.931\tk_average_f1:0.93072\tk_average_auc:0.93051\tk_average_recall:0.931\tk_average_mcc:0.86736\tk_average_Gm:0.93051\t\n",
      "maptiems:15\tenhancetimes:20\tk_average_acc:0.93014\tk_average_f1:0.92981\tk_average_auc:0.92959\tk_average_recall:0.93014\tk_average_mcc:0.86659\tk_average_Gm:0.92959\t\n",
      "maptiems:15\tenhancetimes:25\tk_average_acc:0.93214\tk_average_f1:0.93184\tk_average_auc:0.93162\tk_average_recall:0.93214\tk_average_mcc:0.87038\tk_average_Gm:0.93162\t\n",
      "maptiems:15\tenhancetimes:30\tk_average_acc:0.93375\tk_average_f1:0.93345\tk_average_auc:0.93322\tk_average_recall:0.93375\tk_average_mcc:0.87341\tk_average_Gm:0.93322\t\n",
      "maptiems:15\tenhancetimes:35\tk_average_acc:0.93773\tk_average_f1:0.93747\tk_average_auc:0.93723\tk_average_recall:0.93773\tk_average_mcc:0.88078\tk_average_Gm:0.93723\t\n",
      "maptiems:20\tenhancetimes:15\tk_average_acc:0.93752\tk_average_f1:0.9372\tk_average_auc:0.93692\tk_average_recall:0.93752\tk_average_mcc:0.88139\tk_average_Gm:0.93691\t\n",
      "maptiems:20\tenhancetimes:20\tk_average_acc:0.93615\tk_average_f1:0.93584\tk_average_auc:0.93559\tk_average_recall:0.93615\tk_average_mcc:0.87893\tk_average_Gm:0.93559\t\n",
      "maptiems:20\tenhancetimes:25\tk_average_acc:0.93935\tk_average_f1:0.93909\tk_average_auc:0.93884\tk_average_recall:0.93935\tk_average_mcc:0.8846\tk_average_Gm:0.93883\t\n",
      "maptiems:20\tenhancetimes:30\tk_average_acc:0.94164\tk_average_f1:0.9414\tk_average_auc:0.94115\tk_average_recall:0.94164\tk_average_mcc:0.88874\tk_average_Gm:0.94115\t\n",
      "maptiems:20\tenhancetimes:35\tk_average_acc:0.94267\tk_average_f1:0.94245\tk_average_auc:0.9422\tk_average_recall:0.94267\tk_average_mcc:0.8904\tk_average_Gm:0.9422\t\n",
      "maptiems:25\tenhancetimes:15\tk_average_acc:0.94404\tk_average_f1:0.94388\tk_average_auc:0.94367\tk_average_recall:0.94404\tk_average_mcc:0.89232\tk_average_Gm:0.94367\t\n",
      "maptiems:25\tenhancetimes:20\tk_average_acc:0.9425\tk_average_f1:0.94232\tk_average_auc:0.94209\tk_average_recall:0.9425\tk_average_mcc:0.88946\tk_average_Gm:0.94209\t\n",
      "maptiems:25\tenhancetimes:25\tk_average_acc:0.94656\tk_average_f1:0.9464\tk_average_auc:0.94616\tk_average_recall:0.94656\tk_average_mcc:0.89727\tk_average_Gm:0.94616\t\n",
      "maptiems:25\tenhancetimes:30\tk_average_acc:0.94713\tk_average_f1:0.94697\tk_average_auc:0.94671\tk_average_recall:0.94713\tk_average_mcc:0.8984\tk_average_Gm:0.94671\t\n",
      "maptiems:25\tenhancetimes:35\tk_average_acc:0.94796\tk_average_f1:0.9478\tk_average_auc:0.94755\tk_average_recall:0.94796\tk_average_mcc:0.90002\tk_average_Gm:0.94755\t\n",
      "maptiems:30\tenhancetimes:15\tk_average_acc:0.94851\tk_average_f1:0.94836\tk_average_auc:0.9481\tk_average_recall:0.94851\tk_average_mcc:0.90079\tk_average_Gm:0.9481\t\n",
      "maptiems:30\tenhancetimes:20\tk_average_acc:0.95005\tk_average_f1:0.94991\tk_average_auc:0.94964\tk_average_recall:0.95005\tk_average_mcc:0.90393\tk_average_Gm:0.94964\t\n",
      "maptiems:30\tenhancetimes:25\tk_average_acc:0.95148\tk_average_f1:0.95135\tk_average_auc:0.9511\tk_average_recall:0.95148\tk_average_mcc:0.90661\tk_average_Gm:0.9511\t\n",
      "maptiems:30\tenhancetimes:30\tk_average_acc:0.95134\tk_average_f1:0.95121\tk_average_auc:0.95094\tk_average_recall:0.95134\tk_average_mcc:0.90635\tk_average_Gm:0.95094\t\n",
      "maptiems:30\tenhancetimes:35\tk_average_acc:0.95269\tk_average_f1:0.95257\tk_average_auc:0.9523\tk_average_recall:0.95269\tk_average_mcc:0.9089\tk_average_Gm:0.9523\t\n",
      "maptiems:35\tenhancetimes:15\tk_average_acc:0.95263\tk_average_f1:0.9525\tk_average_auc:0.95221\tk_average_recall:0.95263\tk_average_mcc:0.90879\tk_average_Gm:0.95221\t\n",
      "maptiems:35\tenhancetimes:20\tk_average_acc:0.95348\tk_average_f1:0.95336\tk_average_auc:0.95306\tk_average_recall:0.95348\tk_average_mcc:0.9103\tk_average_Gm:0.95306\t\n",
      "maptiems:35\tenhancetimes:25\tk_average_acc:0.95297\tk_average_f1:0.95285\tk_average_auc:0.95258\tk_average_recall:0.95297\tk_average_mcc:0.90923\tk_average_Gm:0.95258\t\n",
      "maptiems:35\tenhancetimes:30\tk_average_acc:0.95451\tk_average_f1:0.9544\tk_average_auc:0.95414\tk_average_recall:0.95451\tk_average_mcc:0.91224\tk_average_Gm:0.95414\t\n",
      "maptiems:35\tenhancetimes:35\tk_average_acc:0.95434\tk_average_f1:0.95423\tk_average_auc:0.95397\tk_average_recall:0.95434\tk_average_mcc:0.91192\tk_average_Gm:0.95397\t\n"
     ]
    }
   ],
   "source": [
    "k_acc_list, k_f1_list, k_auc_list, k_recall_list, k_mcc_list, k_Gm_list=[],[],[],[],[],[]\n",
    "#这里设置shuffle设置为ture就是打乱顺序在分配\n",
    "kf = KFold(n_splits=3,shuffle=True,random_state=42)\n",
    "for map_times in np.arange(15,36,5):\n",
    "    acc_list_tmp, f1_list_tmp, auc_list_tmp, recall_list_tmp, mcc_list_tmp,Gm_list_tmp=[],[],[],[],[],[]\n",
    "    for enhance_times in np.arange(15, 36,5):\n",
    "        for k, (train, test) in enumerate(kf.split(traindata, trainlabel)):\n",
    "            # kf.split输出的是索引，所以由索引获取交叉后的训练集和测试集及标签\n",
    "            k_train_data,k_train_label = traindata[train], trainlabel[train]\n",
    "            k_test_data,k_test_label = traindata[test], trainlabel[test]           \n",
    "\n",
    "            bls = broadnet(maptimes = map_times, \n",
    "                       enhencetimes = enhance_times,\n",
    "                       map_function = 'relu',\n",
    "                       enhence_function = 'relu',\n",
    "                       batchsize =100,\n",
    "                       reg = 0.001)\n",
    "\n",
    "            #根据训练数据设置权重\n",
    "            weight=bls.addWeight(k_train_label)\n",
    "\n",
    "            #训练\n",
    "            starttime = datetime.datetime.now()\n",
    "            bls.fit(k_train_data,k_train_label,weight)\n",
    "            endtime = datetime.datetime.now()\n",
    "            #print('the training time of BLS is {0} seconds'.format((endtime - starttime).total_seconds()))\n",
    "\n",
    "            #print('k_test_label:', k_test_label)\n",
    "            #预测\n",
    "            k_predict_label = bls.predict(k_test_data)\n",
    "            #print('k_predict_label:', k_predict_label)\n",
    "\n",
    "            #评价指标计算\n",
    "            acc=accuracy_score(k_test_label,k_predict_label,normalize=True)\n",
    "            fmeasure=f1_score(k_test_label,k_predict_label, average='weighted', labels=np.unique(k_test_label))\n",
    "            try:\n",
    "                auc=roc_auc_score(k_test_label,k_predict_label, average='macro', sample_weight=None)\n",
    "            except ValueError:\n",
    "                pass\n",
    "            recall=recall_score(k_test_label, k_predict_label, average='weighted')\n",
    "            MCC=matthews_corrcoef(k_test_label,k_predict_label)\n",
    "            Gmeasure=geometric_mean_score(k_test_label,k_predict_label, average='weighted')\n",
    "\n",
    "            #将此次的十折交叉验证的结果 (10个)保存到pi_list_tmp中\n",
    "            acc_list_tmp.append(acc)\n",
    "            f1_list_tmp.append(fmeasure)\n",
    "            auc_list_tmp.append(auc)\n",
    "            recall_list_tmp.append(recall)\n",
    "            mcc_list_tmp.append(MCC)\n",
    "            Gm_list_tmp.append(Gmeasure)\n",
    "\n",
    "        #求平均保存到k_acc_list中   \n",
    "        k_average_acc=np.mean(acc_list_tmp)\n",
    "        k_average_acc=round(k_average_acc,5)\n",
    "        k_acc_list.append(k_average_acc)\n",
    "\n",
    "        #求平均保存到k_f1_list中   \n",
    "        k_average_f1=np.mean(f1_list_tmp)\n",
    "        k_average_f1=round(k_average_f1,5)\n",
    "        k_f1_list.append(k_average_f1)\n",
    "\n",
    "        #求平均保存到k_auc_list中   \n",
    "        k_average_auc=np.mean(auc_list_tmp)\n",
    "        k_average_auc=round(k_average_auc,5)\n",
    "        k_auc_list.append(k_average_auc)\n",
    "        \n",
    "        #求平均保存到k_recall_list中   \n",
    "        k_average_recall=np.mean(recall_list_tmp)\n",
    "        k_average_recall=round(k_average_recall,5)\n",
    "        k_recall_list.append(k_average_recall)\n",
    "\n",
    "\n",
    "        #求平均保存到k_mcc_list中   \n",
    "        k_average_mcc=np.mean(mcc_list_tmp)\n",
    "        k_average_mcc=round(k_average_mcc,5)\n",
    "        k_mcc_list.append(k_average_mcc)\n",
    "\n",
    "        #求平均保存到k_Gm_list中   \n",
    "        k_average_Gm=np.mean(Gm_list_tmp)\n",
    "        k_average_Gm=round(k_average_Gm,5)\n",
    "        k_Gm_list.append(k_average_Gm)\n",
    "        print(f'maptiems:{map_times}\\tenhancetimes:{enhance_times}\\tk_average_acc:{k_average_acc}\\tk_average_f1:{k_average_f1}\\tk_average_auc:{k_average_auc}\\tk_average_recall:{k_average_recall}\\tk_average_mcc:{k_average_mcc}\\tk_average_Gm:{k_average_Gm}\\t')\n",
    "\n",
    "k_acc_array=np.array(k_acc_list)\n",
    "k_acc_array=k_acc_array.reshape(5,5)\n",
    "# 一维最大值索引\n",
    "#idx_max_ravel = np.argmax(k_acc_array)\n",
    "# true索引\n",
    "#idx_max = np.unravel_index(idx_max_ravel, k_acc_array.shape)\n",
    "#print('max times:',idx_max)\n",
    "\n",
    "k_f1_array=np.array(k_f1_list)\n",
    "k_f1_array=k_f1_array.reshape(5,5)\n",
    "\n",
    "k_auc_array=np.array(k_auc_list)\n",
    "k_auc_array=k_auc_array.reshape(5,5)\n",
    "\n",
    "k_recall_array=np.array(k_recall_list)\n",
    "k_recall_array=k_recall_array.reshape(5,5)\n",
    "\n",
    "k_mcc_array=np.array(k_mcc_list)\n",
    "k_mcc_array=k_mcc_array.reshape(5,5)\n",
    "\n",
    "k_Gm_array=np.array(k_Gm_list)\n",
    "k_Gm_array=k_Gm_array.reshape(5,5)\n",
    "\n",
    "sio.savemat('./data_remember/0.75WBLS_Smote_MC1_MEbest.mat',{'acc':k_acc_array,'f1':k_f1_array,'auc':k_auc_array,'recall':k_recall_array,'mcc':k_mcc_array,'Gm':k_Gm_array})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf01",
   "language": "python",
   "name": "tf01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
