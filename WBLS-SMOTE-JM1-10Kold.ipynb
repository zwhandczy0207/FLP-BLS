{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,recall_score,precision_score,f1_score,roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc</th>\n",
       "      <th>v(g)</th>\n",
       "      <th>ev(g)</th>\n",
       "      <th>iv(g)</th>\n",
       "      <th>n</th>\n",
       "      <th>v</th>\n",
       "      <th>l</th>\n",
       "      <th>d</th>\n",
       "      <th>i</th>\n",
       "      <th>e</th>\n",
       "      <th>...</th>\n",
       "      <th>lOCode</th>\n",
       "      <th>lOComment</th>\n",
       "      <th>lOBlank</th>\n",
       "      <th>locCodeAndComment</th>\n",
       "      <th>uniq_Op</th>\n",
       "      <th>uniq_Opnd</th>\n",
       "      <th>total_Op</th>\n",
       "      <th>total_Opnd</th>\n",
       "      <th>branchCount</th>\n",
       "      <th>defects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>1134.13</td>\n",
       "      <td>0.05</td>\n",
       "      <td>20.31</td>\n",
       "      <td>55.85</td>\n",
       "      <td>23029.10</td>\n",
       "      <td>...</td>\n",
       "      <td>51</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>36</td>\n",
       "      <td>112</td>\n",
       "      <td>86</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>190.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>4348.76</td>\n",
       "      <td>0.06</td>\n",
       "      <td>17.06</td>\n",
       "      <td>254.87</td>\n",
       "      <td>74202.67</td>\n",
       "      <td>...</td>\n",
       "      <td>129</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>135</td>\n",
       "      <td>329</td>\n",
       "      <td>271</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>599.12</td>\n",
       "      <td>0.06</td>\n",
       "      <td>17.19</td>\n",
       "      <td>34.86</td>\n",
       "      <td>10297.30</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>76</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     loc  v(g)  ev(g)  iv(g)      n        v     l      d       i         e  \\\n",
       "0    1.1   1.4    1.4    1.4    1.3     1.30  1.30   1.30    1.30      1.30   \n",
       "1    1.0   1.0    1.0    1.0    1.0     1.00  1.00   1.00    1.00      1.00   \n",
       "2   72.0   7.0    1.0    6.0  198.0  1134.13  0.05  20.31   55.85  23029.10   \n",
       "3  190.0   3.0    1.0    3.0  600.0  4348.76  0.06  17.06  254.87  74202.67   \n",
       "4   37.0   4.0    1.0    4.0  126.0   599.12  0.06  17.19   34.86  10297.30   \n",
       "\n",
       "   ...  lOCode  lOComment  lOBlank  locCodeAndComment  uniq_Op  uniq_Opnd  \\\n",
       "0  ...       2          2        2                  2      1.2        1.2   \n",
       "1  ...       1          1        1                  1        1          1   \n",
       "2  ...      51         10        8                  1       17         36   \n",
       "3  ...     129         29       28                  2       17        135   \n",
       "4  ...      28          1        6                  0       11         16   \n",
       "\n",
       "  total_Op total_Opnd branchCount defects  \n",
       "0      1.2        1.2         1.4   False  \n",
       "1        1          1           1    True  \n",
       "2      112         86          13    True  \n",
       "3      329        271           5    True  \n",
       "4       76         50           7    True  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv(\"../../dataset/NASA/JM1.csv\")\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc</th>\n",
       "      <th>v(g)</th>\n",
       "      <th>ev(g)</th>\n",
       "      <th>iv(g)</th>\n",
       "      <th>n</th>\n",
       "      <th>v</th>\n",
       "      <th>l</th>\n",
       "      <th>d</th>\n",
       "      <th>i</th>\n",
       "      <th>e</th>\n",
       "      <th>b</th>\n",
       "      <th>t</th>\n",
       "      <th>lOCode</th>\n",
       "      <th>lOComment</th>\n",
       "      <th>lOBlank</th>\n",
       "      <th>locCodeAndComment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10885.000000</td>\n",
       "      <td>10885.000000</td>\n",
       "      <td>10885.000000</td>\n",
       "      <td>10885.000000</td>\n",
       "      <td>10885.000000</td>\n",
       "      <td>10885.000000</td>\n",
       "      <td>10885.000000</td>\n",
       "      <td>10885.000000</td>\n",
       "      <td>10885.000000</td>\n",
       "      <td>1.088500e+04</td>\n",
       "      <td>10885.000000</td>\n",
       "      <td>1.088500e+04</td>\n",
       "      <td>10885.000000</td>\n",
       "      <td>10885.000000</td>\n",
       "      <td>10885.00000</td>\n",
       "      <td>10885.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>42.016178</td>\n",
       "      <td>6.348590</td>\n",
       "      <td>3.401047</td>\n",
       "      <td>4.001599</td>\n",
       "      <td>114.389738</td>\n",
       "      <td>673.758017</td>\n",
       "      <td>0.135335</td>\n",
       "      <td>14.177237</td>\n",
       "      <td>29.439544</td>\n",
       "      <td>3.683637e+04</td>\n",
       "      <td>0.224766</td>\n",
       "      <td>2.046465e+03</td>\n",
       "      <td>26.252274</td>\n",
       "      <td>2.737529</td>\n",
       "      <td>4.62554</td>\n",
       "      <td>0.370785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>76.593332</td>\n",
       "      <td>13.019695</td>\n",
       "      <td>6.771869</td>\n",
       "      <td>9.116889</td>\n",
       "      <td>249.502091</td>\n",
       "      <td>1938.856196</td>\n",
       "      <td>0.160538</td>\n",
       "      <td>18.709900</td>\n",
       "      <td>34.418313</td>\n",
       "      <td>4.343678e+05</td>\n",
       "      <td>0.646408</td>\n",
       "      <td>2.413154e+04</td>\n",
       "      <td>59.611201</td>\n",
       "      <td>9.008608</td>\n",
       "      <td>9.96813</td>\n",
       "      <td>1.907969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>48.430000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>11.860000</td>\n",
       "      <td>1.619400e+02</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>217.130000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>9.090000</td>\n",
       "      <td>21.930000</td>\n",
       "      <td>2.031020e+03</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>1.128300e+02</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>46.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>621.480000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>18.900000</td>\n",
       "      <td>36.780000</td>\n",
       "      <td>1.141643e+04</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>6.342500e+02</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3442.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>402.000000</td>\n",
       "      <td>8441.000000</td>\n",
       "      <td>80843.080000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>418.200000</td>\n",
       "      <td>569.780000</td>\n",
       "      <td>3.107978e+07</td>\n",
       "      <td>26.950000</td>\n",
       "      <td>1.726655e+06</td>\n",
       "      <td>2824.000000</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>447.00000</td>\n",
       "      <td>108.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                loc          v(g)         ev(g)         iv(g)             n  \\\n",
       "count  10885.000000  10885.000000  10885.000000  10885.000000  10885.000000   \n",
       "mean      42.016178      6.348590      3.401047      4.001599    114.389738   \n",
       "std       76.593332     13.019695      6.771869      9.116889    249.502091   \n",
       "min        1.000000      1.000000      1.000000      1.000000      0.000000   \n",
       "25%       11.000000      2.000000      1.000000      1.000000     14.000000   \n",
       "50%       23.000000      3.000000      1.000000      2.000000     49.000000   \n",
       "75%       46.000000      7.000000      3.000000      4.000000    119.000000   \n",
       "max     3442.000000    470.000000    165.000000    402.000000   8441.000000   \n",
       "\n",
       "                  v             l             d             i             e  \\\n",
       "count  10885.000000  10885.000000  10885.000000  10885.000000  1.088500e+04   \n",
       "mean     673.758017      0.135335     14.177237     29.439544  3.683637e+04   \n",
       "std     1938.856196      0.160538     18.709900     34.418313  4.343678e+05   \n",
       "min        0.000000      0.000000      0.000000      0.000000  0.000000e+00   \n",
       "25%       48.430000      0.030000      3.000000     11.860000  1.619400e+02   \n",
       "50%      217.130000      0.080000      9.090000     21.930000  2.031020e+03   \n",
       "75%      621.480000      0.160000     18.900000     36.780000  1.141643e+04   \n",
       "max    80843.080000      1.300000    418.200000    569.780000  3.107978e+07   \n",
       "\n",
       "                  b             t        lOCode     lOComment      lOBlank  \\\n",
       "count  10885.000000  1.088500e+04  10885.000000  10885.000000  10885.00000   \n",
       "mean       0.224766  2.046465e+03     26.252274      2.737529      4.62554   \n",
       "std        0.646408  2.413154e+04     59.611201      9.008608      9.96813   \n",
       "min        0.000000  0.000000e+00      0.000000      0.000000      0.00000   \n",
       "25%        0.020000  9.000000e+00      4.000000      0.000000      0.00000   \n",
       "50%        0.070000  1.128300e+02     13.000000      0.000000      2.00000   \n",
       "75%        0.210000  6.342500e+02     28.000000      2.000000      5.00000   \n",
       "max       26.950000  1.726655e+06   2824.000000    344.000000    447.00000   \n",
       "\n",
       "       locCodeAndComment  \n",
       "count       10885.000000  \n",
       "mean            0.370785  \n",
       "std             1.907969  \n",
       "min             0.000000  \n",
       "25%             0.000000  \n",
       "50%             0.000000  \n",
       "75%             0.000000  \n",
       "max           108.000000  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10885, 22)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.1, 1.4, 1.4, 1.4, 1.3, 1.3, 1.3, 1.3, 1.3, 1.3, 1.3, 1.3, 2, 2,\n",
       "       2, 2, '1.2', '1.2', '1.2', '1.2', '1.4', 0], dtype=object)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2=data1.values\n",
    "for i in range(10885):\n",
    "    if data2[i][21]==True:\n",
    "        data2[i][21]=1\n",
    "    else:\n",
    "        data2[i][21]=0\n",
    "data2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '?'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_595606/4252447615.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '?'"
     ]
    }
   ],
   "source": [
    "X=np.array(data2).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.1,   1.4,   1.4, ...,   1.2,   1.2,   1.4],\n",
       "       [  1. ,   1. ,   1. , ...,   1. ,   1. ,   1. ],\n",
       "       [ 24. ,   5. ,   1. , ...,  44. ,  19. ,   9. ],\n",
       "       ...,\n",
       "       [ 82. ,  11. ,   3. , ..., 285. , 190. ,  21. ],\n",
       "       [ 10. ,   2. ,   1. , ...,  19. ,  13. ,   3. ],\n",
       "       [ 28. ,   6. ,   5. , ...,  67. ,  37. ,  11. ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=X[:,21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X[:,0:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((898, 21), (898,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
    "#os =  RandomOverSampler()\n",
    "X_res, y_res = SMOTE().fit_resample(X, y)\n",
    "X_res.shape,y_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(898, 21)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res.shape\n",
    "#X_res=X_res.reshape(898,21,1)\n",
    "#X_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "\n",
    "def show_accuracy(predictLabel,Label):\n",
    "    Label = np.ravel(Label).tolist()\n",
    "    predictLabel = predictLabel.tolist()\n",
    "    count = 0\n",
    "    for i in range(len(Label)):\n",
    "        if Label[i] == predictLabel[i]:\n",
    "            count += 1\n",
    "    return (round(count/len(Label),5))\n",
    "\n",
    "class node_generator(object):\n",
    "    def __init__(self, whiten = False):\n",
    "        self.Wlist = []\n",
    "        self.blist = []\n",
    "        self.function_num = 0\n",
    "        self.whiten = whiten\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1.0/(1 + np.exp(-x))\n",
    "\n",
    "    def relu(self, x):\n",
    "        return np.maximum(x, 0)\n",
    "\n",
    "    def tanh(self, x):\n",
    "        return (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x))\n",
    "\n",
    "    def linear(self, x):\n",
    "        return x\n",
    "\n",
    "    def orth(self, W):\n",
    "        \"\"\"\n",
    "        目前看来，这个函数应该配合下一个generator函数是生成权重的\n",
    "        \"\"\"\n",
    "        for i in range(0, W.shape[1]):\n",
    "            w = np.mat(W[:,i].copy()).T\n",
    "            w_sum = 0\n",
    "            for j in range(i):\n",
    "                wj = np.mat(W[:,j].copy()).T\n",
    "                w_sum += (w.T.dot(wj))[0,0]*wj\n",
    "            w -= w_sum\n",
    "            w = w/np.sqrt(w.T.dot(w))\n",
    "            W[:,i] = np.ravel(w)\n",
    "\n",
    "        return W\n",
    "\n",
    "    def generator(self, shape, times):\n",
    "        for i in range(times):\n",
    "            random.seed(i)\n",
    "            W = 2*np.random.random(size=shape)-1\n",
    "            if self.whiten == True:\n",
    "                W = self.orth(W)   # 只在增强层使用\n",
    "            b = 2*np.random.random() -1\n",
    "            yield (W, b)\n",
    "\n",
    "    def generator_nodes(self, data, times, batchsize, function_num):\n",
    "        # 按照bls的理论，mapping layer是输入乘以不同的权重加上不同的偏差之后得到的\n",
    "        # 若干组，所以，权重是一个列表，每一个元素可作为权重与输入相乘\n",
    "        self.Wlist = [elem[0] for elem in self.generator((data.shape[1], batchsize), times)]\n",
    "        self.blist = [elem[1] for elem in self.generator((data.shape[1], batchsize), times)]\n",
    "\n",
    "        self.function_num = {'linear':self.linear,\n",
    "                        'sigmoid': self.sigmoid,\n",
    "                        'tanh':self.tanh,\n",
    "                        'relu':self.relu }[function_num]  # 激活函数供不同的层选择\n",
    "        # 下面就是先得到一组mapping nodes，再不断叠加，得到len(Wlist)组mapping nodes\n",
    "        nodes = self.function_num(data.dot(self.Wlist[0]) + self.blist[0])\n",
    "        for i in range(1, len(self.Wlist)):\n",
    "            nodes = np.column_stack((nodes, self.function_num(data.dot(self.Wlist[i])+self.blist[i])))\n",
    "        return nodes\n",
    "\n",
    "    def transform(self,testdata):\n",
    "        testnodes = self.function_num(testdata.dot(self.Wlist[0])+self.blist[0])\n",
    "        for i in range(1,len(self.Wlist)):\n",
    "            testnodes = np.column_stack((testnodes, self.function_num(testdata.dot(self.Wlist[i])+self.blist[i])))\n",
    "        return testnodes\n",
    "\n",
    "class scaler:\n",
    "    def __init__(self):\n",
    "        self._mean = 0\n",
    "        self._std = 0\n",
    "    \n",
    "    def fit_transform(self,traindata):\n",
    "        self._mean = traindata.mean(axis = 0)\n",
    "        self._std = traindata.std(axis = 0)\n",
    "        return (traindata-self._mean)/(self._std+0.001)\n",
    "    \n",
    "    def transform(self,testdata):\n",
    "        return (testdata-self._mean)/(self._std+0.001)\n",
    "\n",
    "class broadnet:\n",
    "    def __init__(self, \n",
    "                 maptimes = 10, \n",
    "                 enhencetimes = 10,\n",
    "                 map_function = 'linear',\n",
    "                 enhence_function = 'linear',\n",
    "                 batchsize = 'auto', \n",
    "                 reg = 0.001):\n",
    "        \n",
    "        self._maptimes = maptimes\n",
    "        self._enhencetimes = enhencetimes\n",
    "        self._batchsize = batchsize\n",
    "        self._reg = reg\n",
    "        self._map_function = map_function\n",
    "        self._enhence_function = enhence_function\n",
    "        \n",
    "        self.W = 0\n",
    "        self.pesuedoinverse = 0\n",
    "        self.normalscaler = scaler()\n",
    "        self.onehotencoder = preprocessing.OneHotEncoder(sparse = False)\n",
    "        self.mapping_generator = node_generator()\n",
    "        self.enhence_generator = node_generator(whiten = True)\n",
    "\n",
    "    def fit(self,data,label,weight):\n",
    "        if self._batchsize == 'auto':\n",
    "            self._batchsize = data.shape[1]\n",
    "        data = self.normalscaler.fit_transform(data)\n",
    "        label = self.onehotencoder.fit_transform(np.mat(label).T)\n",
    "        \n",
    "        mappingdata = self.mapping_generator.generator_nodes(data,self._maptimes,self._batchsize,self._map_function)\n",
    "        enhencedata = self.enhence_generator.generator_nodes(mappingdata,self._enhencetimes,self._batchsize,self._enhence_function)\n",
    "        \n",
    "        #print('number of mapping nodes {0}, number of enhence nodes {1}'.format(mappingdata.shape[1],enhencedata.shape[1]))\n",
    "        #print('mapping nodes maxvalue {0} minvalue {1} '.format(round(np.max(mappingdata),5),round(np.min(mappingdata),5)))\n",
    "        #print('enhence nodes maxvalue {0} minvalue {1} '.format(round(np.max(enhencedata),5),round(np.min(enhencedata),5)))\n",
    "        \n",
    "        inputdata = np.column_stack((mappingdata,enhencedata))\n",
    "        pesuedoinverse = self.pinv(inputdata,self._reg,weight)\n",
    "        self.W =  pesuedoinverse.dot(label)\n",
    "        \n",
    "        #print('W:', self.W)\n",
    "        #print('W:', self.W.shape)  \n",
    "    \n",
    "    #改写伪逆矩阵算法，将权重输入\n",
    "    def pinv(self,A,reg,weight):\n",
    "        return np.mat(reg*np.eye(A.shape[1])+A.T.dot(weight).dot(A)).I.dot(A.T).dot(weight)\n",
    "    \n",
    "    def decode(self,Y_onehot):\n",
    "        Y = []\n",
    "        for i in range(Y_onehot.shape[0]):\n",
    "            lis = np.ravel(Y_onehot[i,:]).tolist()\n",
    "            Y.append(lis.index(max(lis)))\n",
    "        return np.array(Y)\n",
    "    \n",
    "    def accuracy(self,predictlabel,label):\n",
    "        label = np.ravel(label).tolist()\n",
    "        predictlabel = predictlabel.tolist()\n",
    "        count = 0\n",
    "        for i in range(len(label)):\n",
    "            if label[i] == predictlabel[i]:\n",
    "                count += 1\n",
    "        return (round(count/len(label),5))\n",
    "        \n",
    "    def predict(self,testdata):\n",
    "        testdata = self.normalscaler.transform(testdata)\n",
    "        test_mappingdata = self.mapping_generator.transform(testdata)\n",
    "        test_enhencedata = self.enhence_generator.transform(test_mappingdata)\n",
    "        \n",
    "        test_inputdata = np.column_stack((test_mappingdata,test_enhencedata)) \n",
    "        #print('*predictlabel shape:',self.decode(test_inputdata.dot(self.W)).shape)\n",
    "        #print('*predictlabel:', self.decode(test_inputdata.dot(self.W)))\n",
    "        #print('*accuracy:',show_accuracy(self.decode(test_inputdata.dot(self.W)),testlabel))\n",
    "        return self.decode(test_inputdata.dot(self.W))\n",
    "    \n",
    "    def addWeight(self,trainlabel):\n",
    "        #对BLS设置加权，按照训练集中的label比例进行权重设置\n",
    "        #求训练数据集中label为1的个数\n",
    "        count=0\n",
    "        for z in range(len(trainlabel)):\n",
    "            #print ('个数 %d ' %z)\n",
    "            #print('k_train_label:', k_train_label[z])\n",
    "            if trainlabel[z]==1:\n",
    "                count=count+1\n",
    "        #print ('label为1的个数 %d ' %j)\n",
    "        #print(count)\n",
    "        #print(k_train_label.shape)\n",
    "        #print(len(k_train_label))\n",
    "        #权重设置 \n",
    "        weight = np.zeros((len(trainlabel),len(trainlabel)))\n",
    "        for i in range(len(trainlabel)):\n",
    "            if trainlabel[i]==1:\n",
    "                #weight[i,i]=0.618/count\n",
    "                weight[i,i]=2*(len(trainlabel)-count)/len(trainlabel)\n",
    "            else:\n",
    "                #weight[i,i]=1/(len(k_train_label)-count)\n",
    "                weight[i,i]=2*count/len(trainlabel)\n",
    "        #print('Weight:', weight)\n",
    "        return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将数据集划分为训练集和测试集\n",
    "traindata,testdata,trainlabel,testlabel = train_test_split(X_res,y_res,test_size=0.2,random_state = 0)\n",
    "#print(traindata.shape,trainlabel.shape,testdata.shape,testlabel.shape)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2)\n",
    "#y_train = np_utils.to_categorical(y_train)\n",
    "#y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maptiems:15\tenhancetimes:15\tk_average_acc:0.89699\tk_average_f1:0.89668\tk_average_auc:0.89454\tk_average_mcc:0.79595\tk_average_Gm:0.89445\t\n",
      "maptiems:15\tenhancetimes:20\tk_average_acc:0.89072\tk_average_f1:0.89016\tk_average_auc:0.88907\tk_average_mcc:0.78711\tk_average_Gm:0.88898\t\n",
      "maptiems:15\tenhancetimes:25\tk_average_acc:0.89329\tk_average_f1:0.89274\tk_average_auc:0.89139\tk_average_mcc:0.79112\tk_average_Gm:0.89128\t\n",
      "maptiems:15\tenhancetimes:30\tk_average_acc:0.89035\tk_average_f1:0.88981\tk_average_auc:0.88888\tk_average_mcc:0.78614\tk_average_Gm:0.88877\t\n",
      "maptiems:15\tenhancetimes:35\tk_average_acc:0.88749\tk_average_f1:0.88709\tk_average_auc:0.88671\tk_average_mcc:0.7804\tk_average_Gm:0.88662\t\n",
      "maptiems:20\tenhancetimes:15\tk_average_acc:0.88163\tk_average_f1:0.88157\tk_average_auc:0.88229\tk_average_mcc:0.76958\tk_average_Gm:0.88222\t\n",
      "maptiems:20\tenhancetimes:20\tk_average_acc:0.87329\tk_average_f1:0.8732\tk_average_auc:0.87382\tk_average_mcc:0.7518\tk_average_Gm:0.87376\t\n",
      "maptiems:20\tenhancetimes:25\tk_average_acc:0.87974\tk_average_f1:0.8796\tk_average_auc:0.87962\tk_average_mcc:0.76333\tk_average_Gm:0.87956\t\n",
      "maptiems:20\tenhancetimes:30\tk_average_acc:0.88056\tk_average_f1:0.88039\tk_average_auc:0.88048\tk_average_mcc:0.76604\tk_average_Gm:0.88041\t\n",
      "maptiems:20\tenhancetimes:35\tk_average_acc:0.88104\tk_average_f1:0.88083\tk_average_auc:0.88045\tk_average_mcc:0.76669\tk_average_Gm:0.88036\t\n",
      "maptiems:25\tenhancetimes:15\tk_average_acc:0.87469\tk_average_f1:0.87417\tk_average_auc:0.87635\tk_average_mcc:0.76251\tk_average_Gm:0.8762\t\n",
      "maptiems:25\tenhancetimes:20\tk_average_acc:0.88863\tk_average_f1:0.88817\tk_average_auc:0.88911\tk_average_mcc:0.78687\tk_average_Gm:0.88899\t\n",
      "maptiems:25\tenhancetimes:25\tk_average_acc:0.89141\tk_average_f1:0.891\tk_average_auc:0.89128\tk_average_mcc:0.79132\tk_average_Gm:0.89118\t\n",
      "maptiems:25\tenhancetimes:30\tk_average_acc:0.88653\tk_average_f1:0.88622\tk_average_auc:0.88661\tk_average_mcc:0.78109\tk_average_Gm:0.88651\t\n",
      "maptiems:25\tenhancetimes:35\tk_average_acc:0.88889\tk_average_f1:0.8886\tk_average_auc:0.8887\tk_average_mcc:0.78441\tk_average_Gm:0.88862\t\n",
      "maptiems:30\tenhancetimes:15\tk_average_acc:0.87881\tk_average_f1:0.87828\tk_average_auc:0.8793\tk_average_mcc:0.76438\tk_average_Gm:0.87923\t\n",
      "maptiems:30\tenhancetimes:20\tk_average_acc:0.87817\tk_average_f1:0.87797\tk_average_auc:0.87957\tk_average_mcc:0.76362\tk_average_Gm:0.8795\t\n",
      "maptiems:30\tenhancetimes:25\tk_average_acc:0.88306\tk_average_f1:0.88278\tk_average_auc:0.88405\tk_average_mcc:0.77322\tk_average_Gm:0.88398\t\n",
      "maptiems:30\tenhancetimes:30\tk_average_acc:0.88516\tk_average_f1:0.88485\tk_average_auc:0.88556\tk_average_mcc:0.77694\tk_average_Gm:0.88547\t\n",
      "maptiems:30\tenhancetimes:35\tk_average_acc:0.88669\tk_average_f1:0.88635\tk_average_auc:0.8867\tk_average_mcc:0.77941\tk_average_Gm:0.88661\t\n",
      "maptiems:35\tenhancetimes:15\tk_average_acc:0.89834\tk_average_f1:0.89799\tk_average_auc:0.89773\tk_average_mcc:0.80132\tk_average_Gm:0.89766\t\n",
      "maptiems:35\tenhancetimes:20\tk_average_acc:0.89838\tk_average_f1:0.8981\tk_average_auc:0.89798\tk_average_mcc:0.80085\tk_average_Gm:0.89789\t\n",
      "maptiems:35\tenhancetimes:25\tk_average_acc:0.89094\tk_average_f1:0.89057\tk_average_auc:0.89079\tk_average_mcc:0.78721\tk_average_Gm:0.89069\t\n",
      "maptiems:35\tenhancetimes:30\tk_average_acc:0.89454\tk_average_f1:0.89425\tk_average_auc:0.89439\tk_average_mcc:0.79367\tk_average_Gm:0.8943\t\n",
      "maptiems:35\tenhancetimes:35\tk_average_acc:0.89419\tk_average_f1:0.89381\tk_average_auc:0.8935\tk_average_mcc:0.79333\tk_average_Gm:0.8934\t\n"
     ]
    }
   ],
   "source": [
    "k_acc_list, k_f1_list, k_auc_list, k_mcc_list, k_Gm_list=[],[],[],[],[]\n",
    "#这里设置shuffle设置为ture就是打乱顺序在分配\n",
    "kf = KFold(n_splits=10,shuffle=True,random_state=42)\n",
    "for map_times in np.arange(15,36,5):\n",
    "    acc_list_tmp, f1_list_tmp, auc_list_tmp, mcc_list_tmp,Gm_list_tmp=[],[],[],[],[]\n",
    "    for enhance_times in np.arange(15, 36,5):\n",
    "        for k, (train, test) in enumerate(kf.split(traindata, trainlabel)):\n",
    "            # kf.split输出的是索引，所以由索引获取交叉后的训练集和测试集及标签\n",
    "            k_train_data,k_train_label = traindata[train], trainlabel[train]\n",
    "            k_test_data,k_test_label = traindata[test], trainlabel[test]           \n",
    "\n",
    "            bls = broadnet(maptimes = map_times, \n",
    "                       enhencetimes = enhance_times,\n",
    "                       map_function = 'relu',\n",
    "                       enhence_function = 'relu',\n",
    "                       batchsize =100,\n",
    "                       reg = 0.001)\n",
    "\n",
    "            #根据训练数据设置权重\n",
    "            weight=bls.addWeight(k_train_label)\n",
    "\n",
    "            #训练\n",
    "            starttime = datetime.datetime.now()\n",
    "            bls.fit(k_train_data,k_train_label,weight)\n",
    "            endtime = datetime.datetime.now()\n",
    "            #print('the training time of BLS is {0} seconds'.format((endtime - starttime).total_seconds()))\n",
    "\n",
    "            #print('k_test_label:', k_test_label)\n",
    "            #预测\n",
    "            k_predict_label = bls.predict(k_test_data)\n",
    "            #print('k_predict_label:', k_predict_label)\n",
    "\n",
    "            #评价指标计算\n",
    "            acc=accuracy_score(k_test_label,k_predict_label,normalize=True)\n",
    "            fmeasure=f1_score(k_test_label,k_predict_label, average='weighted', labels=np.unique(k_test_label))\n",
    "            try:\n",
    "                auc=roc_auc_score(k_test_label,k_predict_label, average='macro', sample_weight=None)\n",
    "            except ValueError:\n",
    "                pass\n",
    "            MCC=matthews_corrcoef(k_test_label,k_predict_label)\n",
    "            Gmeasure=geometric_mean_score(k_test_label,k_predict_label, average='weighted')\n",
    "\n",
    "            #将此次的十折交叉验证的结果 (10个)保存到pi_list_tmp中\n",
    "            acc_list_tmp.append(acc)\n",
    "            f1_list_tmp.append(fmeasure)\n",
    "            auc_list_tmp.append(auc)\n",
    "            mcc_list_tmp.append(MCC)\n",
    "            Gm_list_tmp.append(Gmeasure)\n",
    "\n",
    "        #求平均保存到k_acc_list中   \n",
    "        k_average_acc=np.mean(acc_list_tmp)\n",
    "        k_average_acc=round(k_average_acc,5)\n",
    "        k_acc_list.append(k_average_acc)\n",
    "\n",
    "        #求平均保存到k_f1_list中   \n",
    "        k_average_f1=np.mean(f1_list_tmp)\n",
    "        k_average_f1=round(k_average_f1,5)\n",
    "        k_f1_list.append(k_average_f1)\n",
    "\n",
    "        #求平均保存到k_auc_list中   \n",
    "        k_average_auc=np.mean(auc_list_tmp)\n",
    "        k_average_auc=round(k_average_auc,5)\n",
    "        k_auc_list.append(k_average_auc)\n",
    "\n",
    "        #求平均保存到k_mcc_list中   \n",
    "        k_average_mcc=np.mean(mcc_list_tmp)\n",
    "        k_average_mcc=round(k_average_mcc,5)\n",
    "        k_mcc_list.append(k_average_mcc)\n",
    "\n",
    "        #求平均保存到k_Gm_list中   \n",
    "        k_average_Gm=np.mean(Gm_list_tmp)\n",
    "        k_average_Gm=round(k_average_Gm,5)\n",
    "        k_Gm_list.append(k_average_Gm)\n",
    "        print(f'maptiems:{map_times}\\tenhancetimes:{enhance_times}\\tk_average_acc:{k_average_acc}\\tk_average_f1:{k_average_f1}\\tk_average_auc:{k_average_auc}\\tk_average_mcc:{k_average_mcc}\\tk_average_Gm:{k_average_Gm}\\t')\n",
    "\n",
    "k_acc_array=np.array(k_acc_list)\n",
    "k_acc_array=k_acc_array.reshape(5,5)\n",
    "# 一维最大值索引\n",
    "#idx_max_ravel = np.argmax(k_acc_array)\n",
    "# true索引\n",
    "#idx_max = np.unravel_index(idx_max_ravel, k_acc_array.shape)\n",
    "#print('max times:',idx_max)\n",
    "\n",
    "k_f1_array=np.array(k_f1_list)\n",
    "k_f1_array=k_f1_array.reshape(5,5)\n",
    "\n",
    "k_auc_array=np.array(k_auc_list)\n",
    "k_auc_array=k_auc_array.reshape(5,5)\n",
    "\n",
    "k_mcc_array=np.array(k_mcc_list)\n",
    "k_mcc_array=k_mcc_array.reshape(5,5)\n",
    "\n",
    "k_Gm_array=np.array(k_Gm_list)\n",
    "k_Gm_array=k_Gm_array.reshape(5,5)\n",
    "\n",
    "sio.savemat('./data_remember/WBLS_Smote_CM1_MEbest.mat',{'acc':k_acc_array,'f1':k_f1_array,'auc':k_auc_array,'mcc':k_mcc_array,'Gm':k_Gm_array})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'broadnet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_585110/2280405382.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m bls = broadnet(maptimes = 35, \n\u001b[0m\u001b[1;32m      2\u001b[0m                        \u001b[0menhencetimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                        \u001b[0mmap_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                        \u001b[0menhence_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                        \u001b[0mbatchsize\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'broadnet' is not defined"
     ]
    }
   ],
   "source": [
    "starttime = datetime.datetime.now()\n",
    "bls.fit(X_train,y_train)\n",
    "endtime = datetime.datetime.now()\n",
    "print('the training time of BLS is {0} seconds'.format((endtime - starttime).total_seconds()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92222\n"
     ]
    }
   ],
   "source": [
    "predictlabel = bls.predict(X_test)\n",
    "print(show_accuracy(predictlabel,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9222222222222223"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_test, predictlabel（真实值，预测值）\n",
    "\n",
    "#使用sklearn库实现\n",
    "#ACC \n",
    "#accurary(准确率)：也就是说真实值是1，预测值也是1；真实值为0，预测值也为0。就是正确的分类，这是我们评价模型的最重要的一个指标\n",
    "from sklearn.metrics import accuracy_score\n",
    "#accuracy_score(y_test, predictlabel)\n",
    "accurary=accuracy_score(y_test, predictlabel, normalize=True)#normalize：默认值为True，返回正确分类的比例；如果为False，返回正确分类的样本数\n",
    "accurary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8910891089108911"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#precision(精准率)：假如预测的正类的个数和预测个数的比重。 数值越高，就是表示越对\n",
    "from sklearn.metrics import precision_score\n",
    "precision=precision_score(y_test, predictlabel)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.967741935483871"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recall(召回率）：样本中的正例有多少被预测正确了。真实值是正例1，在正例预测中所占的比重。假如我们比较考虑类别1的预测能力，可以使用这个标准。 数值越高 就是找的越全。\n",
    "from sklearn.metrics import recall_score\n",
    "recall=recall_score(y_test, predictlabel)\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9278350515463919"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#F1：综合评价一个模型的拟合能力。\n",
    "#F-measure\n",
    "from sklearn.metrics import f1_score\n",
    "F1=f1_score(y_test, predictlabel)\n",
    "F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 绘制P-R曲线\n",
    "# #P-R曲线（精准率—召回率）：准确率和召回率互相影响，理想状态下肯定追求两个都高，但是实际情况是两者相互“制约”：追求准确率高，则召回率就低；追求召回率高，则通常会影响准确率。若两者都低，则一般是出了某种问题。\n",
    "# import matplotlib.pyplot as plt\n",
    "# def plot_pr_curve(rec_ls, pre_ls, pr_value=None, title=None):\n",
    "#     label = \"AUPR: \" + str(pr_value)\n",
    "#     plt.plot(rec_ls, pre_ls, 'r-', )\n",
    "#     plt.plot([0, 1], [1, 0], 'k--', linewidth=0.8, label=label)\n",
    "#     plt.axis([0, 1, 0, 1])\n",
    "#     plt.xlabel('Recall')\n",
    "#     plt.ylabel('Precision')\n",
    "#     plt.title(title)\n",
    "#     plt.legend(loc=\"lower left\")  # 若需显示label,必须在show之前加这一句\n",
    "#     plt.show()\n",
    "# plot_pr_curve(recall, precision,\"P-R Curve\",'Precision/Recall Curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.        , 0.12643678, 1.        ]),\n",
       " array([0.        , 0.96774194, 1.        ]),\n",
       " array([2, 1, 0]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#计算ROC曲线的横纵坐标值，TPR，FPR\n",
    "#TPR = TP/(TP+FN) = recall(真正例率，敏感度)       FPR = FP/(FP+TN)(假正例率，1-特异性)\n",
    "from sklearn.metrics import roc_curve\n",
    "roc_curve(y_test, predictlabel, pos_label=None, sample_weight=None, drop_intermediate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9206525769373378"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AUC  \n",
    "#计算ROC曲线下的面积就是AUC的值，the larger the better，值越大越好\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test, predictlabel, average='macro', sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8471892131665406"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MCC\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "matthews_corrcoef(y_test, predictlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf01",
   "language": "python",
   "name": "tf01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
