{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,recall_score,precision_score,f1_score,roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOC_BLANK</th>\n",
       "      <th>BRANCH_COUNT</th>\n",
       "      <th>CALL_PAIRS</th>\n",
       "      <th>LOC_CODE_AND_COMMENT</th>\n",
       "      <th>LOC_COMMENTS</th>\n",
       "      <th>CONDITION_COUNT</th>\n",
       "      <th>CYCLOMATIC_COMPLEXITY</th>\n",
       "      <th>CYCLOMATIC_DENSITY</th>\n",
       "      <th>DECISION_COUNT</th>\n",
       "      <th>DECISION_DENSITY</th>\n",
       "      <th>...</th>\n",
       "      <th>NODE_COUNT</th>\n",
       "      <th>NORMALIZED_CYLOMATIC_COMPLEXITY</th>\n",
       "      <th>NUM_OPERANDS</th>\n",
       "      <th>NUM_OPERATORS</th>\n",
       "      <th>NUM_UNIQUE_OPERANDS</th>\n",
       "      <th>NUM_UNIQUE_OPERATORS</th>\n",
       "      <th>NUMBER_OF_LINES</th>\n",
       "      <th>PERCENT_COMMENTS</th>\n",
       "      <th>LOC_TOTAL</th>\n",
       "      <th>Defective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>0.23</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>0.15</td>\n",
       "      <td>51</td>\n",
       "      <td>59</td>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "      <td>41</td>\n",
       "      <td>11.54</td>\n",
       "      <td>26</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.14</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>57.14</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>0.28</td>\n",
       "      <td>10</td>\n",
       "      <td>2.4</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>0.17</td>\n",
       "      <td>63</td>\n",
       "      <td>89</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>66</td>\n",
       "      <td>33.33</td>\n",
       "      <td>39</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.26</td>\n",
       "      <td>8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>0.14</td>\n",
       "      <td>47</td>\n",
       "      <td>60</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>72</td>\n",
       "      <td>29.41</td>\n",
       "      <td>39</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.18</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.11</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>9.09</td>\n",
       "      <td>11</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LOC_BLANK  BRANCH_COUNT  CALL_PAIRS  LOC_CODE_AND_COMMENT  LOC_COMMENTS  \\\n",
       "0         14            11           4                     3             0   \n",
       "1          6             3           1                     1             3   \n",
       "2         14            19           6                     5            12   \n",
       "3         20            17           2                     3            12   \n",
       "4          6             3           6                     1             0   \n",
       "\n",
       "   CONDITION_COUNT  CYCLOMATIC_COMPLEXITY  CYCLOMATIC_DENSITY  DECISION_COUNT  \\\n",
       "0               20                      6                0.23              10   \n",
       "1                4                      2                0.50               2   \n",
       "2               24                     11                0.28              10   \n",
       "3               20                     10                0.26               8   \n",
       "4                4                      2                0.18               2   \n",
       "\n",
       "   DECISION_DENSITY  ...  NODE_COUNT  NORMALIZED_CYLOMATIC_COMPLEXITY  \\\n",
       "0               2.0  ...          22                             0.15   \n",
       "1               2.0  ...           5                             0.14   \n",
       "2               2.4  ...          28                             0.17   \n",
       "3               2.5  ...          23                             0.14   \n",
       "4               2.0  ...          10                             0.11   \n",
       "\n",
       "   NUM_OPERANDS  NUM_OPERATORS  NUM_UNIQUE_OPERANDS  NUM_UNIQUE_OPERATORS  \\\n",
       "0            51             59                   27                    15   \n",
       "1             4              7                    4                     6   \n",
       "2            63             89                   33                    25   \n",
       "3            47             60                   28                    23   \n",
       "4            23             25                   15                     9   \n",
       "\n",
       "   NUMBER_OF_LINES  PERCENT_COMMENTS  LOC_TOTAL  Defective  \n",
       "0               41             11.54         26          N  \n",
       "1               14             57.14          4          N  \n",
       "2               66             33.33         39          N  \n",
       "3               72             29.41         39          N  \n",
       "4               18              9.09         11          Y  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv(\"../../dataset/NASA/PC3.csv\")\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOC_BLANK</th>\n",
       "      <th>BRANCH_COUNT</th>\n",
       "      <th>CALL_PAIRS</th>\n",
       "      <th>LOC_CODE_AND_COMMENT</th>\n",
       "      <th>LOC_COMMENTS</th>\n",
       "      <th>CONDITION_COUNT</th>\n",
       "      <th>CYCLOMATIC_COMPLEXITY</th>\n",
       "      <th>CYCLOMATIC_DENSITY</th>\n",
       "      <th>DECISION_COUNT</th>\n",
       "      <th>DECISION_DENSITY</th>\n",
       "      <th>...</th>\n",
       "      <th>MULTIPLE_CONDITION_COUNT</th>\n",
       "      <th>NODE_COUNT</th>\n",
       "      <th>NORMALIZED_CYLOMATIC_COMPLEXITY</th>\n",
       "      <th>NUM_OPERANDS</th>\n",
       "      <th>NUM_OPERATORS</th>\n",
       "      <th>NUM_UNIQUE_OPERANDS</th>\n",
       "      <th>NUM_UNIQUE_OPERATORS</th>\n",
       "      <th>NUMBER_OF_LINES</th>\n",
       "      <th>PERCENT_COMMENTS</th>\n",
       "      <th>LOC_TOTAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1099.000000</td>\n",
       "      <td>1099.000000</td>\n",
       "      <td>1099.000000</td>\n",
       "      <td>1099.000000</td>\n",
       "      <td>1099.000000</td>\n",
       "      <td>1099.000000</td>\n",
       "      <td>1099.000000</td>\n",
       "      <td>1099.000000</td>\n",
       "      <td>1099.000000</td>\n",
       "      <td>1099.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1099.000000</td>\n",
       "      <td>1099.000000</td>\n",
       "      <td>1099.000000</td>\n",
       "      <td>1099.000000</td>\n",
       "      <td>1099.000000</td>\n",
       "      <td>1099.000000</td>\n",
       "      <td>1099.000000</td>\n",
       "      <td>1099.000000</td>\n",
       "      <td>1099.000000</td>\n",
       "      <td>1099.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.133758</td>\n",
       "      <td>12.330300</td>\n",
       "      <td>2.866242</td>\n",
       "      <td>1.706096</td>\n",
       "      <td>5.582348</td>\n",
       "      <td>20.145587</td>\n",
       "      <td>6.850773</td>\n",
       "      <td>0.274813</td>\n",
       "      <td>9.393995</td>\n",
       "      <td>2.173549</td>\n",
       "      <td>...</td>\n",
       "      <td>10.161965</td>\n",
       "      <td>22.384895</td>\n",
       "      <td>0.194422</td>\n",
       "      <td>71.347589</td>\n",
       "      <td>87.817106</td>\n",
       "      <td>27.371247</td>\n",
       "      <td>15.095541</td>\n",
       "      <td>44.748863</td>\n",
       "      <td>15.883194</td>\n",
       "      <td>29.515924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.177896</td>\n",
       "      <td>23.500593</td>\n",
       "      <td>3.125973</td>\n",
       "      <td>3.541077</td>\n",
       "      <td>10.332685</td>\n",
       "      <td>44.146724</td>\n",
       "      <td>12.037340</td>\n",
       "      <td>0.130341</td>\n",
       "      <td>21.381273</td>\n",
       "      <td>0.364159</td>\n",
       "      <td>...</td>\n",
       "      <td>22.203299</td>\n",
       "      <td>40.047583</td>\n",
       "      <td>0.114276</td>\n",
       "      <td>180.614694</td>\n",
       "      <td>222.931647</td>\n",
       "      <td>43.945700</td>\n",
       "      <td>6.320880</td>\n",
       "      <td>59.019159</td>\n",
       "      <td>18.856796</td>\n",
       "      <td>47.644789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>71.500000</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>28.285000</td>\n",
       "      <td>32.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>589.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>1148.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>574.000000</td>\n",
       "      <td>963.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>4015.000000</td>\n",
       "      <td>5590.000000</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>89.470000</td>\n",
       "      <td>817.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         LOC_BLANK  BRANCH_COUNT   CALL_PAIRS  LOC_CODE_AND_COMMENT  \\\n",
       "count  1099.000000   1099.000000  1099.000000           1099.000000   \n",
       "mean      8.133758     12.330300     2.866242              1.706096   \n",
       "std      10.177896     23.500593     3.125973              3.541077   \n",
       "min       0.000000      1.000000     0.000000              0.000000   \n",
       "25%       1.000000      5.000000     1.000000              0.000000   \n",
       "50%       4.000000      7.000000     2.000000              0.000000   \n",
       "75%      12.000000     13.000000     4.000000              2.000000   \n",
       "max      77.000000    589.000000    24.000000             42.000000   \n",
       "\n",
       "       LOC_COMMENTS  CONDITION_COUNT  CYCLOMATIC_COMPLEXITY  \\\n",
       "count   1099.000000      1099.000000            1099.000000   \n",
       "mean       5.582348        20.145587               6.850773   \n",
       "std       10.332685        44.146724              12.037340   \n",
       "min        0.000000         4.000000               1.000000   \n",
       "25%        0.000000         6.000000               3.000000   \n",
       "50%        1.000000        12.000000               4.000000   \n",
       "75%        7.000000        20.000000               7.000000   \n",
       "max       78.000000      1148.000000             299.000000   \n",
       "\n",
       "       CYCLOMATIC_DENSITY  DECISION_COUNT  DECISION_DENSITY  ...  \\\n",
       "count         1099.000000     1099.000000       1099.000000  ...   \n",
       "mean             0.274813        9.393995          2.173549  ...   \n",
       "std              0.130341       21.381273          0.364159  ...   \n",
       "min              0.010000        2.000000          2.000000  ...   \n",
       "25%              0.180000        2.000000          2.000000  ...   \n",
       "50%              0.250000        4.000000          2.000000  ...   \n",
       "75%              0.330000       10.000000          2.200000  ...   \n",
       "max              0.750000      570.000000          5.000000  ...   \n",
       "\n",
       "       MULTIPLE_CONDITION_COUNT   NODE_COUNT  NORMALIZED_CYLOMATIC_COMPLEXITY  \\\n",
       "count               1099.000000  1099.000000                      1099.000000   \n",
       "mean                  10.161965    22.384895                         0.194422   \n",
       "std                   22.203299    40.047583                         0.114276   \n",
       "min                    2.000000     2.000000                         0.010000   \n",
       "25%                    3.000000     9.000000                         0.100000   \n",
       "50%                    6.000000    13.000000                         0.170000   \n",
       "75%                   10.000000    23.000000                         0.260000   \n",
       "max                  574.000000   963.000000                         0.600000   \n",
       "\n",
       "       NUM_OPERANDS  NUM_OPERATORS  NUM_UNIQUE_OPERANDS  NUM_UNIQUE_OPERATORS  \\\n",
       "count   1099.000000    1099.000000          1099.000000           1099.000000   \n",
       "mean      71.347589      87.817106            27.371247             15.095541   \n",
       "std      180.614694     222.931647            43.945700              6.320880   \n",
       "min        2.000000       5.000000             2.000000              4.000000   \n",
       "25%       18.000000      24.000000            10.000000             11.000000   \n",
       "50%       35.000000      45.000000            17.000000             14.000000   \n",
       "75%       71.500000      87.500000            32.000000             18.000000   \n",
       "max     4015.000000    5590.000000           787.000000             68.000000   \n",
       "\n",
       "       NUMBER_OF_LINES  PERCENT_COMMENTS    LOC_TOTAL  \n",
       "count      1099.000000       1099.000000  1099.000000  \n",
       "mean         44.748863         15.883194    29.515924  \n",
       "std          59.019159         18.856796    47.644789  \n",
       "min           4.000000          0.000000     3.000000  \n",
       "25%          14.000000          0.000000    10.000000  \n",
       "50%          26.000000          8.700000    18.000000  \n",
       "75%          55.000000         28.285000    32.500000  \n",
       "max         891.000000         89.470000   817.000000  \n",
       "\n",
       "[8 rows x 37 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1099, 38)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 3, 1, 1, 3, 4, 2, 0.5, 2, 2.0, 2, 1.0, 5, 1, 0.0, 3, 1, 12.18,\n",
       "       3.0, 109.62, 0.01, 11, 0.33, 6.09, 36.54, 0.5, 1, 2, 5, 0.14, 4, 7,\n",
       "       4, 6, 14, 57.14, 4, 0], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2=data1.values\n",
    "for i in range(1099):\n",
    "    if data2[i][37]==\"Y\":\n",
    "        data2[i][37]=1\n",
    "    else:\n",
    "        data2[i][37]=0\n",
    "data2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(data2).astype(float)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14.  , 11.  ,  4.  , ..., 41.  , 11.54, 26.  ],\n",
       "       [ 6.  ,  3.  ,  1.  , ..., 14.  , 57.14,  4.  ],\n",
       "       [14.  , 19.  ,  6.  , ..., 66.  , 33.33, 39.  ],\n",
       "       ...,\n",
       "       [ 0.  ,  3.  ,  0.  , ...,  9.  ,  0.  ,  8.  ],\n",
       "       [ 0.  ,  3.  ,  0.  , ...,  8.  ,  0.  ,  7.  ],\n",
       "       [ 1.  ,  3.  ,  1.  , ...,  8.  ,  0.  ,  6.  ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,:37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=X[:,37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X[:,0:37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1922, 37), (1922,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
    "#os =  RandomOverSampler()\n",
    "X_res, y_res = SMOTE().fit_resample(X, y)\n",
    "X_res.shape,y_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1922, 37)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res.shape\n",
    "#X_res=X_res.reshape(898,21,1)\n",
    "#X_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import csv\n",
    "import time\n",
    "\n",
    "def show_accuracy(predictLabel,Label):\n",
    "    Label = np.ravel(Label).tolist()\n",
    "    predictLabel = predictLabel.tolist()\n",
    "    count = 0\n",
    "    for i in range(len(Label)):\n",
    "        if Label[i] == predictLabel[i]:\n",
    "            count += 1\n",
    "    return (round(count/len(Label),5))\n",
    "\n",
    "class node_generator(object):\n",
    "    def __init__(self, whiten = False):\n",
    "        self.Wlist = []\n",
    "        self.blist = []\n",
    "        self.function_num = 0\n",
    "        self.whiten = whiten\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1.0/(1 + np.exp(-x))\n",
    "\n",
    "    def relu(self, x):\n",
    "        return np.maximum(x, 0)\n",
    "\n",
    "    def tanh(self, x):\n",
    "        return (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x))\n",
    "\n",
    "    def linear(self, x):\n",
    "        return x\n",
    "\n",
    "    def orth(self, W):\n",
    "        \"\"\"\n",
    "        目前看来，这个函数应该配合下一个generator函数是生成权重的\n",
    "        \"\"\"\n",
    "        for i in range(0, W.shape[1]):\n",
    "            w = np.mat(W[:,i].copy()).T\n",
    "            w_sum = 0\n",
    "            for j in range(i):\n",
    "                wj = np.mat(W[:,j].copy()).T\n",
    "                w_sum += (w.T.dot(wj))[0,0]*wj\n",
    "            w -= w_sum\n",
    "            w = w/np.sqrt(w.T.dot(w))\n",
    "            W[:,i] = np.ravel(w)\n",
    "\n",
    "        return W\n",
    "\n",
    "    def generator(self, shape, times):\n",
    "        for i in range(times):\n",
    "            random.seed(i)\n",
    "            W = 2*np.random.random(size=shape)-1\n",
    "            if self.whiten == True:\n",
    "                W = self.orth(W)   # 只在增强层使用\n",
    "            b = 2*np.random.random() -1\n",
    "            yield (W, b)\n",
    "\n",
    "    def generator_nodes(self, data, times, batchsize, function_num):\n",
    "        # 按照bls的理论，mapping layer是输入乘以不同的权重加上不同的偏差之后得到的\n",
    "        # 若干组，所以，权重是一个列表，每一个元素可作为权重与输入相乘\n",
    "        self.Wlist = [elem[0] for elem in self.generator((data.shape[1], batchsize), times)]\n",
    "        self.blist = [elem[1] for elem in self.generator((data.shape[1], batchsize), times)]\n",
    "\n",
    "        self.function_num = {'linear':self.linear,\n",
    "                        'sigmoid': self.sigmoid,\n",
    "                        'tanh':self.tanh,\n",
    "                        'relu':self.relu }[function_num]  # 激活函数供不同的层选择\n",
    "        # 下面就是先得到一组mapping nodes，再不断叠加，得到len(Wlist)组mapping nodes\n",
    "        nodes = self.function_num(data.dot(self.Wlist[0]) + self.blist[0])\n",
    "        for i in range(1, len(self.Wlist)):\n",
    "            nodes = np.column_stack((nodes, self.function_num(data.dot(self.Wlist[i])+self.blist[i])))\n",
    "        return nodes\n",
    "\n",
    "    def transform(self,testdata):\n",
    "        testnodes = self.function_num(testdata.dot(self.Wlist[0])+self.blist[0])\n",
    "        for i in range(1,len(self.Wlist)):\n",
    "            testnodes = np.column_stack((testnodes, self.function_num(testdata.dot(self.Wlist[i])+self.blist[i])))\n",
    "        return testnodes\n",
    "\n",
    "class scaler:\n",
    "    def __init__(self):\n",
    "        self._mean = 0\n",
    "        self._std = 0\n",
    "    \n",
    "    def fit_transform(self,traindata):\n",
    "        self._mean = traindata.mean(axis = 0)\n",
    "        self._std = traindata.std(axis = 0)\n",
    "        return (traindata-self._mean)/(self._std+0.001)\n",
    "    \n",
    "    def transform(self,testdata):\n",
    "        return (testdata-self._mean)/(self._std+0.001)\n",
    "\n",
    "class broadnet:\n",
    "    def __init__(self, \n",
    "                 maptimes = 10, \n",
    "                 enhencetimes = 10,\n",
    "                 map_function = 'linear',\n",
    "                 enhence_function = 'linear',\n",
    "                 batchsize = 'auto', \n",
    "                 reg = 0.001):\n",
    "        \n",
    "        self._maptimes = maptimes\n",
    "        self._enhencetimes = enhencetimes\n",
    "        self._batchsize = batchsize\n",
    "        self._reg = reg\n",
    "        self._map_function = map_function\n",
    "        self._enhence_function = enhence_function\n",
    "        \n",
    "        self.W = 0\n",
    "        self.pesuedoinverse = 0\n",
    "        self.normalscaler = scaler()\n",
    "        self.onehotencoder = preprocessing.OneHotEncoder(sparse = False)\n",
    "        self.mapping_generator = node_generator()\n",
    "        self.enhence_generator = node_generator(whiten = True)\n",
    "\n",
    "    def fit(self,data,label,weight):\n",
    "        if self._batchsize == 'auto':\n",
    "            self._batchsize = data.shape[1]\n",
    "        data = self.normalscaler.fit_transform(data)\n",
    "        label = self.onehotencoder.fit_transform(np.mat(label).T)\n",
    "        \n",
    "        mappingdata = self.mapping_generator.generator_nodes(data,self._maptimes,self._batchsize,self._map_function)\n",
    "        enhencedata = self.enhence_generator.generator_nodes(mappingdata,self._enhencetimes,self._batchsize,self._enhence_function)\n",
    "        \n",
    "        #print('number of mapping nodes {0}, number of enhence nodes {1}'.format(mappingdata.shape[1],enhencedata.shape[1]))\n",
    "        #print('mapping nodes maxvalue {0} minvalue {1} '.format(round(np.max(mappingdata),5),round(np.min(mappingdata),5)))\n",
    "        #print('enhence nodes maxvalue {0} minvalue {1} '.format(round(np.max(enhencedata),5),round(np.min(enhencedata),5)))\n",
    "        \n",
    "        inputdata = np.column_stack((mappingdata,enhencedata))\n",
    "        pesuedoinverse = self.pinv(inputdata,self._reg,weight)\n",
    "        self.W =  pesuedoinverse.dot(label)\n",
    "        \n",
    "        #print('W:', self.W)\n",
    "        #print('W:', self.W.shape)  \n",
    "    \n",
    "    #改写伪逆矩阵算法，将权重输入\n",
    "    def pinv(self,A,reg,weight):\n",
    "        return np.mat(reg*np.eye(A.shape[1])+A.T.dot(weight).dot(A)).I.dot(A.T).dot(weight)\n",
    "    \n",
    "    def decode(self,Y_onehot):\n",
    "        Y = []\n",
    "        for i in range(Y_onehot.shape[0]):\n",
    "            lis = np.ravel(Y_onehot[i,:]).tolist()\n",
    "            Y.append(lis.index(max(lis)))\n",
    "        return np.array(Y)\n",
    "    \n",
    "    def accuracy(self,predictlabel,label):\n",
    "        label = np.ravel(label).tolist()\n",
    "        predictlabel = predictlabel.tolist()\n",
    "        count = 0\n",
    "        for i in range(len(label)):\n",
    "            if label[i] == predictlabel[i]:\n",
    "                count += 1\n",
    "        return (round(count/len(label),5))\n",
    "        \n",
    "    def predict(self,testdata):\n",
    "        testdata = self.normalscaler.transform(testdata)\n",
    "        test_mappingdata = self.mapping_generator.transform(testdata)\n",
    "        test_enhencedata = self.enhence_generator.transform(test_mappingdata)\n",
    "        \n",
    "        test_inputdata = np.column_stack((test_mappingdata,test_enhencedata)) \n",
    "        #print('*predictlabel shape:',self.decode(test_inputdata.dot(self.W)).shape)\n",
    "        #print('*predictlabel:', self.decode(test_inputdata.dot(self.W)))\n",
    "        #print('*accuracy:',show_accuracy(self.decode(test_inputdata.dot(self.W)),testlabel))\n",
    "        return self.decode(test_inputdata.dot(self.W))\n",
    "    \n",
    "    def addWeight(self,trainlabel):\n",
    "        #对BLS设置加权，按照训练集中的label比例进行权重设置\n",
    "        #求训练数据集中label为1的个数\n",
    "        count=0\n",
    "        for z in range(len(trainlabel)):\n",
    "            #print ('个数 %d ' %z)\n",
    "            #print('k_train_label:', k_train_label[z])\n",
    "            if trainlabel[z]==1:\n",
    "                count=count+1\n",
    "        #print ('label为1的个数 %d ' %j)\n",
    "        #print(count)\n",
    "        #print(k_train_label.shape)\n",
    "        #print(len(k_train_label))\n",
    "        #权重设置 \n",
    "        weight = np.zeros((len(trainlabel),len(trainlabel)))\n",
    "        for i in range(len(trainlabel)):\n",
    "            if trainlabel[i]==1:\n",
    "                #weight[i,i]=0.618/count\n",
    "                weight[i,i]=2*(len(trainlabel)-count)/len(trainlabel)\n",
    "            else:\n",
    "                #weight[i,i]=1/(len(k_train_label)-count)\n",
    "                weight[i,i]=2*count/len(trainlabel)\n",
    "        #print('Weight:', weight)\n",
    "        return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将数据集划分为训练集和测试集\n",
    "#traindata,testdata,trainlabel,testlabel = train_test_split(X_res,y_res,test_size=0.2,random_state = 0)\n",
    "#print(traindata.shape,trainlabel.shape,testdata.shape,testlabel.shape)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2)\n",
    "#y_train = np_utils.to_categorical(y_train)\n",
    "#y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainingTime：10.286055,acc：0.952183,fmeasure：0.952164,auc：0.952144,recall：0.952183,MCC：0.904992,Gmeasure：0.952144\n",
      "trainingTime：10.528102,acc：0.914761,fmeasure：0.914486,auc：0.915681,recall：0.914761,MCC：0.836762,Gmeasure：0.915681\n",
      "trainingTime：10.536150,acc：0.877339,fmeasure：0.876670,auc：0.876612,recall：0.877339,MCC：0.761526,Gmeasure：0.876612\n",
      "trainingTime：10.541722,acc：0.925156,fmeasure：0.925020,auc：0.925438,recall：0.925156,MCC：0.853968,Gmeasure：0.925438\n",
      "trainingTime：10.599533,acc：0.904366,fmeasure：0.903556,auc：0.902159,recall：0.904366,MCC：0.818152,Gmeasure：0.902157\n",
      "trainingTime：10.662175,acc：0.885655,fmeasure：0.884887,auc：0.884253,recall：0.885655,MCC：0.778949,Gmeasure：0.884252\n",
      "trainingTime：10.661711,acc：0.945946,fmeasure：0.945791,auc：0.944782,recall：0.945946,MCC：0.894687,Gmeasure：0.944781\n",
      "trainingTime：10.647969,acc：0.906445,fmeasure：0.905962,auc：0.906013,recall：0.906445,MCC：0.820497,Gmeasure：0.906013\n",
      "trainingTime：10.683904,acc：0.864865,fmeasure：0.863994,auc：0.864380,recall：0.864865,MCC：0.738266,Gmeasure：0.864380\n",
      "trainingTime：10.642601,acc：0.912682,fmeasure：0.912398,auc：0.913321,recall：0.912682,MCC：0.832054,Gmeasure：0.913321\n"
     ]
    }
   ],
   "source": [
    "Evaluat_list=[]\n",
    "for i in np.arange(0,10):\n",
    "    #将数据集划分为训练集和测试集\n",
    "    traindata,testdata,trainlabel,testlabel = train_test_split(X_res,y_res,test_size=0.25,random_state = i)\n",
    "    bls = broadnet(maptimes = 35, \n",
    "               enhencetimes = 35,\n",
    "               map_function = 'relu',\n",
    "               enhence_function = 'relu',\n",
    "               batchsize =100,\n",
    "               reg = 0.001)\n",
    "\n",
    "    #根据训练数据设置权重\n",
    "    weight=bls.addWeight(trainlabel)\n",
    "\n",
    "    #训练\n",
    "    starttime = datetime.datetime.now()\n",
    "    bls.fit(traindata,trainlabel,weight)\n",
    "    endtime = datetime.datetime.now()\n",
    "    trainingTime=(endtime - starttime).total_seconds()\n",
    "    #print('the training time of BLS is {0} seconds'.format((endtime - starttime).total_seconds()))\n",
    "\n",
    "    #预测\n",
    "    predictlabel = bls.predict(testdata)\n",
    "\n",
    "    #评价指标计算\n",
    "    acc=accuracy_score(testlabel,predictlabel,normalize=True)\n",
    "    fmeasure=f1_score(testlabel,predictlabel, average='weighted', labels=np.unique(testlabel))\n",
    "    try:\n",
    "        auc=roc_auc_score(testlabel,predictlabel, average='macro', sample_weight=None)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    MCC=matthews_corrcoef(testlabel,predictlabel)\n",
    "    Gmeasure=geometric_mean_score(testlabel,predictlabel, average='weighted')\n",
    "    recall=recall_score(testlabel, predictlabel, average='weighted')\n",
    "\n",
    "    print('trainingTime：%f,acc：%f,fmeasure：%f,auc：%f,recall：%f,MCC：%f,Gmeasure：%f'%(trainingTime,acc,fmeasure,auc,recall,MCC,Gmeasure))\n",
    "    Evaluat_tuple=(trainingTime,acc,fmeasure,auc,recall,MCC,Gmeasure)    \n",
    "    Evaluat_list.append(Evaluat_tuple)\n",
    "\n",
    "# 表头\n",
    "header = ['trainTime', 'acc', 'fmeasure', 'auc','recall', 'MCC', 'Gmeasure']\n",
    "with open('./data_remember/0.75WBLS_Smote_PC3_Evaluat.csv', 'w', encoding='utf-8', newline='') as file_obj:\n",
    "    # 创建对象\n",
    "    writer = csv.writer(file_obj)\n",
    "    # 写表头\n",
    "    writer.writerow(header)\n",
    "    # 3.写入数据(一次性写入多行)\n",
    "    writer.writerows(Evaluat_list)\n",
    "\n",
    "\n",
    "    #sio.savemat('./data_remember/WBLS_Smote_CM1_test.mat',{'time':format((endtime - starttime).total_seconds()),'acc':acc,'f1':fmeasure,'auc':auc,'mcc':MCC,'Gm':Gmeasure})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf01",
   "language": "python",
   "name": "tf01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
